"""
æ— äººæœºç§»åŠ¨ç¯å¢ƒ - DQNè®­ç»ƒ
ä½¿ç”¨ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼ˆ6æ–¹å‘ä½ç§»ï¼‰ç›´æ¥æ§åˆ¶æ— äººæœºç§»åŠ¨
"""
import numpy as np
import gymnasium as gym
from gymnasium import spaces
import os
import json
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger("MovementEnv")


class MovementEnv(gym.Env):
    """
    æ— äººæœºç§»åŠ¨å­¦ä¹ ç¯å¢ƒ
    
    åŠ¨ä½œç©ºé—´: 6ä¸ªç¦»æ•£åŠ¨ä½œï¼ˆä¸Š/ä¸‹/å·¦/å³/å‰/åï¼‰
    è§‚å¯Ÿç©ºé—´: ä½ç½®ã€é€Ÿåº¦ã€ç†µå€¼ã€leaderä½ç½®ç­‰
    """
    
    def __init__(self, server=None, drone_name="UAV1", config_path=None):
        super(MovementEnv, self).__init__()
        
        self.server = server
        self.drone_name = drone_name
        
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        print(f"[OK] ç§»åŠ¨DQNç¯å¢ƒå·²åŠ è½½é…ç½®")
        
        # åŠ¨ä½œç©ºé—´: 6ä¸ªç¦»æ•£åŠ¨ä½œ
        # 0: å‘ä¸Š, 1: å‘ä¸‹, 2: å‘å·¦, 3: å‘å³, 4: å‘å‰, 5: å‘å
        self.action_space = spaces.Discrete(6)
        
        # è§‚å¯Ÿç©ºé—´ç»´åº¦è¯´æ˜ï¼š
        # - ä½ç½®(3): x, y, z
        # - é€Ÿåº¦(3): vx, vy, vz
        # - æœå‘(3): forward_x, forward_y, forward_z
        # - å±€éƒ¨ç†µå€¼ç»Ÿè®¡(3): å¹³å‡ç†µ, æœ€å¤§ç†µ, ç†µæ ‡å‡†å·®
        # - Leaderç›¸å¯¹ä½ç½®(3): dx, dy, dz
        # - LeaderèŒƒå›´ä¿¡æ¯(2): è·ç¦», æ˜¯å¦è¶Šç•Œ
        # - æ‰«æè¿›åº¦(3): å·²æ‰«ææ¯”ä¾‹, å·²æ‰«ææ•°é‡, æœªæ‰«ææ•°é‡
        # - å…¶ä»–æ— äººæœºæœ€è¿‘è·ç¦»(1)
        # - ç”µé‡ä¿¡æ¯(2): å½“å‰ç”µå‹, å‰©ä½™ç”µé‡ç™¾åˆ†æ¯”
        # æ€»è®¡: 23ç»´
        self.observation_space = spaces.Box(
            low=-np.inf,
            high=np.inf,
            shape=(23,),
            dtype=np.float32
        )
        
        # åŠ¨ä½œåˆ°ä½ç§»çš„æ˜ å°„ï¼ˆå•ä½ï¼šç±³ï¼‰
        self.action_step = self.config['movement']['step_size']
        self.action_map = {
            0: np.array([0, 0, self.action_step]),      # ä¸Š
            1: np.array([0, 0, -self.action_step]),     # ä¸‹
            2: np.array([-self.action_step, 0, 0]),     # å·¦
            3: np.array([self.action_step, 0, 0]),      # å³
            4: np.array([0, self.action_step, 0]),      # å‰
            5: np.array([0, -self.action_step, 0])      # å
        }
        
        # çŠ¶æ€è®°å½•
        self.prev_scanned_cells = 0
        self.prev_position = None
        self.prev_entropy_sum = 0
        self.step_count = 0
        self.episode_reward = 0
        
        self.collision_count = 0
        self.out_of_range_count = 0
        
        # é¦–æ¬¡é‡ç½®æ ‡å¿—ï¼ˆç”¨äºè·³è¿‡å¯åŠ¨æ—¶çš„é‡ç½®ï¼‰
        self._first_reset = True
    
    def _load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            config_path = os.path.join(current_dir, "movement_dqn_config.json")
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # è¿”å›é»˜è®¤é…ç½®
            return self._default_config()
    
    def _default_config(self):
        """é»˜è®¤é…ç½®"""
        return {
            "movement": {
                "step_size": 1.0,
                "max_steps": 500
            },
            "rewards": {
                "exploration": 10.0,
                "collision": -50.0,
                "out_of_range": -30.0,
                "smooth_movement": 1.0,
                "entropy_reduction": 5.0,
                "high_entropy_exploration": 5.0,
                "entropy_gradient_bonus": 2.0,
                "step_penalty": -0.1,
                "success": 100.0,
                "height_penalty": -5.0,
                "optimal_height_bonus": 1.0
            },
            "thresholds": {
                "collision_distance": 2.0,
                "scanned_entropy": 30.0,
                "nearby_entropy_distance": 10.0,
                "success_scan_ratio": 0.95,
                "high_entropy_threshold": 40.0,
                "min_scan_height": 2.0,
                "max_scan_height": 15.0,
                "optimal_scan_height": 8.0
            }
        }
    
    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒ"""
        print(f"[DQNç¯å¢ƒ] reset() è¢«è°ƒç”¨")
        if seed is not None:
            np.random.seed(seed)
        
        # é¦–æ¬¡é‡ç½®ï¼šè·³è¿‡ç¯å¢ƒé‡ç½®ï¼ˆå› ä¸ºæ— äººæœºåˆšèµ·é£ï¼Œé¢†å¯¼è€…åˆšå¼€å§‹ç§»åŠ¨ï¼‰
        if self._first_reset:
            self._first_reset = False
            print(f"[DQNç¯å¢ƒ] ğŸš€ é¦–æ¬¡resetï¼Œè·³è¿‡ç¯å¢ƒé‡ç½®ï¼Œç›´æ¥åˆå§‹åŒ–çŠ¶æ€")
            # ä»…é‡ç½®ç”µé‡ï¼ˆç¡®ä¿ç”µé‡ä»æ»¡ç”µå¼€å§‹ï¼‰
            if self.server and hasattr(self.server, 'reset_battery_voltage'):
                self.server.reset_battery_voltage(self.drone_name)
        else:
            # åç»­é‡ç½®ï¼šæ‰§è¡Œå®Œæ•´çš„ç¯å¢ƒé‡ç½®ï¼ˆEpisodeç»“æŸï¼‰
            if self.server:
                print(f"[DQNç¯å¢ƒ] ğŸ”„ Episodeç»“æŸï¼Œæ‰§è¡Œå®Œæ•´ç¯å¢ƒé‡ç½®...")
                self.server.reset_environment()
                # é‡ç½®ç”µé‡
                if hasattr(self.server, 'reset_battery_voltage'):
                    self.server.reset_battery_voltage(self.drone_name)
                import time
                time.sleep(1.0)  # ç­‰å¾…Unityå®Œæˆé‡ç½®
                print(f"[DQNç¯å¢ƒ] âœ… ç¯å¢ƒé‡ç½®å®Œæˆ")
        
        print(f"[DQNç¯å¢ƒ] åˆå§‹åŒ–çŠ¶æ€...")
        self.prev_scanned_cells = self._count_scanned_cells()
        self.prev_entropy_sum = self._get_total_entropy()
        self.prev_position = None
        self.step_count = 0
        self.episode_reward = 0
        self.collision_count = 0
        self.out_of_range_count = 0
        
        print(f"[DQNç¯å¢ƒ] åˆå§‹åŒ–ä¿¡æ¯:")
        print(f"  - åˆå§‹æ‰«ææ•°: {self.prev_scanned_cells}")
        print(f"  - åˆå§‹æ€»ç†„å€¼: {self.prev_entropy_sum:.2f}")
        
        print(f"[DQNç¯å¢ƒ] è·å–åˆå§‹çŠ¶æ€...")
        state = self._get_state()
        print(f"[DQNç¯å¢ƒ] reset() å®Œæˆï¼ŒçŠ¶æ€shape: {state.shape}")
        return state, {}
    
    def step(self, action):
        """
        æ‰§è¡Œä¸€æ­¥åŠ¨ä½œ
        
        :param action: 0-5çš„æ•´æ•°ï¼Œè¡¨ç¤º6ä¸ªç§»åŠ¨æ–¹å‘
        :return: observation, reward, terminated, truncated, info
        """
        # ç¡®ä¿actionæ˜¯æ•´æ•°ï¼ˆä»numpyæ•°ç»„è½¬æ¢ï¼‰
        if hasattr(action, 'item'):
            action = action.item()
        action = int(action)
        
        print(f"[DQNç¯å¢ƒ] step({action}) è¢«è°ƒç”¨")
        
        # è®°å½•å½“å‰ä½ç½®
        print(f"[DQNç¯å¢ƒ] è·å–å½“å‰çŠ¶æ€...")
        current_state = self._get_state()
        print(f"[DQNç¯å¢ƒ] å½“å‰çŠ¶æ€è·å–å®Œæˆ")
        
        # å°†åŠ¨ä½œè½¬æ¢ä¸ºä½ç§»å‘é‡
        displacement = self.action_map[action]
        
        # å‘é€ç§»åŠ¨æŒ‡ä»¤åˆ°serverï¼ˆå¦‚æœè¿æ¥ï¼‰
        if self.server:
            print(f"[DQNç¯å¢ƒ] å‘é€ç§»åŠ¨æŒ‡ä»¤: {displacement}")
            self._apply_movement(displacement)
            print(f"[DQNç¯å¢ƒ] ç§»åŠ¨æŒ‡ä»¤å·²å‘é€")
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©ç¯å¢ƒæ›´æ–°
        if self.server:
            import time
            time.sleep(0.05)  # 50ms
            print(f"[DQNç¯å¢ƒ] ç­‰å¾…å®Œæˆ")
        
        # è·å–æ–°çŠ¶æ€
        print(f"[DQNç¯å¢ƒ] è·å–æ–°çŠ¶æ€...")
        next_state = self._get_state()
        print(f"[DQNç¯å¢ƒ] æ–°çŠ¶æ€è·å–å®Œæˆ")
        
        # è®¡ç®—å¥–åŠ±
        print(f"[DQNç¯å¢ƒ] è®¡ç®—å¥–åŠ±...")
        reward = self._calculate_reward(action, current_state, next_state)
        self.episode_reward += reward
        print(f"[DQNç¯å¢ƒ] å¥–åŠ±è®¡ç®—å®Œæˆ: {reward:.2f}")
        
        # åˆ¤æ–­æ˜¯å¦ç»“æŸ
        self.step_count += 1
        terminated = self._check_done()  # episodeè‡ªç„¶ç»“æŸ
        truncated = False  # ä¸ä½¿ç”¨æˆªæ–­
        
        # é¢å¤–ä¿¡æ¯
        info = {
            'action': action,
            'displacement': displacement.tolist(),
            'scanned_cells': self._count_scanned_cells(),
            'collision_count': self.collision_count,
            'out_of_range_count': self.out_of_range_count,
            'episode_reward': self.episode_reward
        }
        
        if self.step_count % 10 == 0:
            print(f"[DQNç¯å¢ƒ] æ­¥éª¤ {self.step_count}, å¥–åŠ±: {reward:.2f}, episodeæ€»å¥–åŠ±: {self.episode_reward:.2f}")
        
        return next_state, reward, terminated, truncated, info
    
    def _get_state(self):
        """è·å–å½“å‰è§‚å¯ŸçŠ¶æ€ï¼ˆ23ç»´ï¼šåŒ…å«ç”µé‡ä¿¡æ¯ï¼‰"""
        if not self.server:
            # æµ‹è¯•æ¨¡å¼ï¼šè¿”å›éšæœºçŠ¶æ€
            return np.random.randn(23).astype(np.float32)
            
        try:
            # åˆ†ç¦»é”çš„è·å–ï¼Œé¿å…æ­»é”
            # ç¬¬ä¸€æ­¥ï¼šä» runtime_data è·å–æ— äººæœºçŠ¶æ€
            with self.server.data_lock:
                runtime_data = self.server.unity_runtime_data.get(self.drone_name)
                if not runtime_data:
                    print(f"[DQNç¯å¢ƒ] è­¦å‘Š: æ— äººæœº {self.drone_name} çš„runtime_dataä¸å­˜åœ¨ï¼Œè¿”å›é›¶çŠ¶æ€")
                    return np.zeros(23, dtype=np.float32)
                    
                # 1. ä½ç½® (3)
                pos = runtime_data.position
                position = np.array([pos.x, pos.y, pos.z], dtype=np.float32)
                    
                # 2. é€Ÿåº¦ (3)
                vel = runtime_data.finalMoveDir
                velocity = np.array([
                    vel.x * self.server.config_data.moveSpeed,
                    vel.y * self.server.config_data.moveSpeed,
                    vel.z * self.server.config_data.moveSpeed
                ], dtype=np.float32)
                    
                # 3. æœå‘ (3)
                fwd = runtime_data.forward
                direction = np.array([fwd.x, fwd.y, fwd.z], dtype=np.float32)
                    
                # 5. Leaderç›¸å¯¹ä½ç½® (3)
                if runtime_data.leader_position:
                    leader_rel = np.array([
                        runtime_data.leader_position.x - pos.x,
                        runtime_data.leader_position.y - pos.y,
                        runtime_data.leader_position.z - pos.z
                    ], dtype=np.float32)
                else:
                    leader_rel = np.zeros(3, dtype=np.float32)
                    
                # 6. LeaderèŒƒå›´ä¿¡æ¯ (2)
                if runtime_data.leader_position and runtime_data.leader_scan_radius > 0:
                    dist_to_leader = np.linalg.norm(leader_rel)
                    is_out_of_range = 1.0 if dist_to_leader > runtime_data.leader_scan_radius else 0.0
                    leader_range = np.array([dist_to_leader, is_out_of_range], dtype=np.float32)
                else:
                    leader_range = np.zeros(2, dtype=np.float32)
                
            # ç¬¬äºŒæ­¥ï¼šä» grid_data è·å–ç½‘æ ¼ä¿¡æ¯
            with self.server.grid_lock:
                grid_data = self.server.grid_data
                if not grid_data or not grid_data.cells:
                    print(f"[DQNç¯å¢ƒ] è­¦å‘Š: grid_data ä¸ºç©ºæˆ–æ²¡æœ‰cellsï¼Œè¿”å›é›¶çŠ¶æ€")
                    # è¿”å›å¸¦æœ‰åŸºæœ¬ä¿¡æ¯çš„çŠ¶æ€
                    entropy_info = np.array([50.0, 50.0, 0.0], dtype=np.float32)
                    scan_info = np.array([0.0, 0.0, 0.0], dtype=np.float32)
                    min_dist_array = np.array([100.0], dtype=np.float32)
                else:
                    # 4. å±€éƒ¨ç†™å€¼ç»Ÿè®¡ (3)
                    entropy_info = self._get_entropy_info(grid_data, pos)
                        
                    # 7. æ‰«æè¿›åº¦ (3)
                    scan_info = self._get_scan_info(grid_data)
                        
                    # 8. æœ€è¿‘æ— äººæœºè·ç¦» (1) - éœ€è¦ runtime_dataï¼Œç¨åå•ç‹¬è·å–
                    min_dist_array = np.array([100.0], dtype=np.float32)  # é»˜è®¤å€¼
                
            # ç¬¬ä¸‰æ­¥ï¼šè·å–å…¶ä»–æ— äººæœºè·ç¦»ï¼ˆéœ€è¦é‡æ–°è·å– data_lockï¼‰
            with self.server.data_lock:
                runtime_data = self.server.unity_runtime_data.get(self.drone_name)
                if runtime_data:
                    min_dist = self._get_min_distance_to_others(runtime_data)
                    min_dist_array = np.array([min_dist], dtype=np.float32)
                
            # è·å–ç”µé‡ä¿¡æ¯ (2)
            battery_info = self._get_battery_info()
            
            # ç»„åˆçŠ¶æ€å‘é‡
            state = np.concatenate([
                position,           # 3
                velocity,           # 3
                direction,          # 3
                entropy_info,       # 3
                leader_rel,         # 3
                leader_range,       # 2
                scan_info,          # 3
                min_dist_array,     # 1
                battery_info        # 2
            ])
                
            return state
                
        except Exception as e:
            print(f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return np.zeros(23, dtype=np.float32)
    
    def _calculate_reward(self, action, prev_state, next_state):
        """è®¡ç®—å¥–åŠ±"""
        if not self.server:
            return 0.0
        
        reward = 0.0
        cfg_reward = self.config['rewards']
        cfg_thresh = self.config['thresholds']
        
        try:
            with self.server.data_lock:
                runtime_data = self.server.unity_runtime_data[self.drone_name]
                pos = runtime_data.position
                
                # 0. è®¡ç®—ç¨³å®šæ€§ç³»æ•° (åŸºäºåˆ° Leader çš„è·ç¦»)
                stability_factor = 1.0
                dist_to_leader = 0.0
                if runtime_data.leader_position and runtime_data.leader_scan_radius > 0:
                    dist_to_leader = np.sqrt(
                        (pos.x - runtime_data.leader_position.x) ** 2 +
                        (pos.y - runtime_data.leader_position.y) ** 2 +
                        (pos.z - runtime_data.leader_position.z) ** 2
                    )
                    radius = runtime_data.leader_scan_radius
                    dist_ratio = dist_to_leader / radius
                    
                    # ä»é…ç½®è·å–æ¯”ä¾‹
                    safe_ratio = cfg_thresh.get('stability_safe_ratio', 0.7)
                    penalty_ratio = cfg_thresh.get('stability_penalty_ratio', 0.8)
                    
                    if dist_ratio > 1.0:
                        stability_factor = 0.0  # è¶Šç•Œåå®Œå…¨å–æ¶ˆæ¢ç´¢å¥–åŠ±ï¼Œå¼ºåˆ¶å…¶è¿”å›
                    elif dist_ratio > safe_ratio:
                        # åœ¨ safe_ratio - 1.0 ä¹‹é—´çº¿æ€§è¡°å‡ï¼Œä» 1.0 é™è‡³ 0.1
                        stability_factor = 1.0 - (dist_ratio - safe_ratio) / (1.0 - safe_ratio) * 0.9
                    
                    # é¢å¤–ç¨³å®šæ€§æƒ©ç½šï¼šé è¿‘è¾¹ç•Œæˆ–è¶Šç•Œæ—¶ç»™äºˆè´Ÿåé¦ˆ
                    if dist_ratio > penalty_ratio:
                        # å¼•å¯¼æ— äººæœºè¿œç¦»è¾¹ç•Œ
                        penalty_weight = cfg_reward.get('stability_penalty_weight', 20.0)
                        reward -= (dist_ratio - penalty_ratio) * penalty_weight

                # 1. æ¢ç´¢å¥–åŠ±ï¼šæ–°æ‰«æçš„å•å…ƒæ ¼ (å—ç¨³å®šæ€§ç³»æ•°å½±å“)
                current_scanned = self._count_scanned_cells()
                new_scanned = current_scanned - self.prev_scanned_cells
                if new_scanned > 0:
                    reward += new_scanned * cfg_reward['exploration'] * stability_factor
                self.prev_scanned_cells = current_scanned
                
                # 2. ç†µå€¼é™ä½å¥–åŠ± (å—ç¨³å®šæ€§ç³»æ•°å½±å“)
                current_entropy = self._get_total_entropy()
                entropy_reduced = self.prev_entropy_sum - current_entropy
                if entropy_reduced > 0:
                    reward += entropy_reduced * cfg_reward['entropy_reduction'] * stability_factor
                self.prev_entropy_sum = current_entropy
                
                # 3. ã€ä¼˜åŒ–ã€‘å±€éƒ¨é«˜ç†µæ¢ç´¢å¥–åŠ± - ä»…åœ¨ç¨³å®šæ—¶å¼•å¯¼æ— äººæœºå¯»æ‰¾é«˜ç†µåŒºåŸŸ
                # ä¿®æ­£ç´¢å¼•ï¼š0-2ä½ç½®, 3-5é€Ÿåº¦, 6-8æ–¹å‘, 9-11ç†µä¿¡æ¯
                local_avg_entropy = next_state[9]  # å±€éƒ¨å¹³å‡ç†µ
                local_max_entropy = next_state[10] # å±€éƒ¨æœ€å¤§ç†µ
                
                # å¥–åŠ±è¿›å…¥é«˜ç†µåŒºåŸŸçš„è¡Œä¸º (å—ç¨³å®šæ€§ç³»æ•°å½±å“)
                if local_max_entropy > cfg_thresh.get('high_entropy_threshold', 40.0):
                    entropy_exploration_bonus = cfg_reward.get('high_entropy_exploration', 5.0)
                    reward += entropy_exploration_bonus * stability_factor
                    
                # å¥–åŠ±å‘é«˜ç†µæ–¹å‘ç§»åŠ¨ (å—ç¨³å®šæ€§ç³»æ•°å½±å“)
                if self.prev_position:
                    prev_local_avg_entropy = prev_state[9]
                    entropy_increase = local_avg_entropy - prev_local_avg_entropy
                    if entropy_increase > 0:
                        entropy_gradient_reward = entropy_increase * cfg_reward.get('entropy_gradient_bonus', 2.0)
                        reward += entropy_gradient_reward * stability_factor
                
                # 4. é«˜åº¦æ§åˆ¶å¥–åŠ±/æƒ©ç½š
                current_height = pos.z
                
                # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†çš„æ‰«æé«˜åº¦èŒƒå›´å†…
                min_scan_height = cfg_thresh.get('min_scan_height', 2.0)
                max_scan_height = cfg_thresh.get('max_scan_height', 15.0)
                optimal_height = cfg_thresh.get('optimal_scan_height', 8.0)
                
                if current_height < min_scan_height:
                    # é£å¾—å¤ªä½
                    reward += cfg_reward.get('height_penalty', -5.0)
                elif current_height > max_scan_height:
                    # é£å¾—å¤ªé«˜
                    reward += cfg_reward.get('height_penalty', -5.0)
                elif abs(current_height - optimal_height) < 2.0:
                    # åœ¨æœ€ä½³æ‰«æé«˜åº¦é™„è¿‘
                    reward += cfg_reward.get('optimal_height_bonus', 1.0)
                
                # 5. ç¢°æ’æƒ©ç½š
                min_dist = self._get_min_distance_to_others(runtime_data)
                if min_dist < cfg_thresh['collision_distance']:
                    reward += cfg_reward['collision']
                    self.collision_count += 1
                
                # 6. è¶Šç•Œæƒ©ç½š
                if runtime_data.leader_position and runtime_data.leader_scan_radius > 0:
                    if dist_to_leader > runtime_data.leader_scan_radius:
                        reward += cfg_reward['out_of_range']
                        self.out_of_range_count += 1
                
                # 7. å¹³æ»‘è¿åŠ¨å¥–åŠ±
                if self.prev_position:
                    current_pos = runtime_data.position
                    movement = np.sqrt(
                        (current_pos.x - self.prev_position.x) ** 2 +
                        (current_pos.y - self.prev_position.y) ** 2 +
                        (current_pos.z - self.prev_position.z) ** 2
                    )
                    # é¼“åŠ±é€‚åº¦ç§»åŠ¨
                    if 0.5 < movement < 5.0:
                        reward += cfg_reward['smooth_movement']
                
                self.prev_position = runtime_data.position
                
                # 8. æ¯æ­¥å°æƒ©ç½šï¼ˆé¼“åŠ±å¿«é€Ÿå®Œæˆï¼‰
                reward += cfg_reward['step_penalty']
                
                # 9. æˆåŠŸå¥–åŠ±
                scan_ratio = self._get_scan_ratio()
                if scan_ratio >= cfg_thresh['success_scan_ratio']:
                    reward += cfg_reward['success']
                
                # 10. ç”µé‡å¥–åŠ±ä¸æƒ©ç½š
                if hasattr(self.server, 'get_battery_voltage'):
                    current_voltage = self.server.get_battery_voltage(self.drone_name)
                    battery_info = self.server.battery_manager.get_battery_info(self.drone_name)
                    if battery_info:
                        remaining_pct = battery_info.get_remaining_percentage()
                        
                        # ç”µé‡è¿‡ä½æƒ©ç½š
                        if 'battery_low_threshold' in cfg_thresh and current_voltage < cfg_thresh['battery_low_threshold']:
                            penalty = cfg_reward.get('battery_low_penalty', 10.0)
                            reward -= penalty
                        
                        # ç”µé‡æœ€ä¼˜èŒƒå›´å¥–åŠ±
                        if 'battery_optimal_min' in cfg_thresh and 'battery_optimal_max' in cfg_thresh:
                            if cfg_thresh['battery_optimal_min'] <= current_voltage <= cfg_thresh['battery_optimal_max']:
                                bonus = cfg_reward.get('battery_optimal_reward', 2.0)
                                reward += bonus
                
                # æ¯ä¸ªåŠ¨ä½œéƒ½æ›´æ–°ç”µé‡æ¶ˆè€—
                if hasattr(self.server, 'update_battery_voltage'):
                    action_intensity = 0.5  # åŠ¨ä½œå¼ºåº¦ï¼Œå¯æ ¹æ®å®é™…åŠ¨ä½œè°ƒæ•´
                    self.server.update_battery_voltage(self.drone_name, action_intensity)
                
        except Exception as e:
            print(f"è®¡ç®—å¥–åŠ±å¤±è´¥: {str(e)}")
        
        return reward
    
    def _check_done(self):
        """åˆ¤æ–­episodeæ˜¯å¦ç»“æŸ"""
        # è¾¾åˆ°æœ€å¤§æ­¥æ•°
        if self.step_count >= self.config['movement']['max_steps']:
            print(f"[DQNç¯å¢ƒ] Episode ç»“æŸ: è¾¾åˆ°æœ€å¤§æ­¥æ•° {self.step_count}/{self.config['movement']['max_steps']}")
            return True
        
        # æ‰«æå®Œæˆ
        scan_ratio = self._get_scan_ratio()
        if scan_ratio >= self.config['thresholds']['success_scan_ratio']:
            print(f"[DQNç¯å¢ƒ] Episode ç»“æŸ: æ‰«æå®Œæˆ {scan_ratio:.2%} >= {self.config['thresholds']['success_scan_ratio']:.2%}")
            return True
        
        # ç¢°æ’æ¬¡æ•°è¿‡å¤š
        if self.collision_count >= 10:
            print(f"[DQNç¯å¢ƒ] Episode ç»“æŸ: ç¢°æ’æ¬¡æ•°è¿‡å¤š {self.collision_count}/10")
            return True
        
        # [DEBUG] æ‰“å°å½“å‰çŠ¶æ€ï¼ˆä»…å‰10æ­¥ï¼‰
        if self.step_count <= 10:
            print(f"[DQNç¯å¢ƒ] _check_done() - æ­¥éª¤ {self.step_count}: scan_ratio={scan_ratio:.2%}, collision={self.collision_count}, out_of_range={self.out_of_range_count}")
        
        return False
    
    def _apply_movement(self, displacement):
        """åº”ç”¨ç§»åŠ¨åˆ°æ— äººæœºï¼ˆé€šè¿‡AlgorithmServerçš„DQNæ§åˆ¶æ¨¡å¼ï¼‰"""
        if not self.server:
            return  # æ²¡æœ‰serverè¿æ¥ï¼Œæ— æ³•æ§åˆ¶
        
        try:
            # æ£€æŸ¥serveræ˜¯å¦å¤„äºŠDQNæ§åˆ¶æ¨¡å¼
            if not hasattr(self.server, 'control_mode') or self.server.control_mode != 'dqn':
                logger.warning("è­¦å‘Š: AlgorithmServeræœªå¤„äºDQNæ§åˆ¶æ¨¡å¼ï¼Œç§»åŠ¨æŒ‡ä»¤å¯èƒ½ä¸ä¼šç”Ÿæ•ˆ")
                return
            
            # å°†ä½ç§»è½¬æ¢ä¸ºUnityåæ ‡ç³»çš„æ–¹å‘å‘é‡
            # displacementæ˜¯NumPyæ•°ç»„: [dx, dy, dz]
            # éœ€è¦è½¬æ¢ä¸ºVector3å¯¹è±¡ï¼ˆUnityåæ ‡ç³»ï¼‰
            from Algorithm.Vector3 import Vector3
            
            # è®¡ç®—å½’ä¸€åŒ–çš„æ–¹å‘å‘é‡
            magnitude = np.linalg.norm(displacement)
            if magnitude > 1e-6:
                # å½’ä¸€åŒ–æ–¹å‘
                direction = displacement / magnitude
                # è½¬æ¢ä¸ºVector3ï¼ˆUnityåæ ‡ç³»ï¼šX=å‰åï¼ŒY=é«˜åº¦ï¼ŒZ=å·¦å³ï¼‰
                move_direction = Vector3(direction[0], direction[1], direction[2])
            else:
                # ä½ç§»è¿‡å°ï¼Œä¸ç§»åŠ¨
                move_direction = Vector3(0, 0, 0)
            
            # é€šè¿‡AlgorithmServerè®¾ç½®DQNç§»åŠ¨æŒ‡ä»¤
            self.server.set_dqn_movement(self.drone_name, move_direction)
            
        except Exception as e:
            import traceback
            logger.error(f"åº”ç”¨ç§»åŠ¨å¤±è´¥: {str(e)}")
            logger.debug(traceback.format_exc())
    
    def _get_entropy_info(self, grid_data, position):
        """è·å–å±€éƒ¨ç†µå€¼ç»Ÿè®¡"""
        if not grid_data or not grid_data.cells:
            return np.array([50.0, 50.0, 0.0], dtype=np.float32)
        
        nearby_distance = self.config['thresholds']['nearby_entropy_distance']
        
        # æ‰¾é™„è¿‘å•å…ƒæ ¼
        nearby_cells = [
            cell for cell in grid_data.cells[:100]
            if np.sqrt(
                (cell.center.x - position.x) ** 2 +
                (cell.center.y - position.y) ** 2 +
                (cell.center.z - position.z) ** 2
            ) < nearby_distance
        ]
        
        if not nearby_cells:
            return np.array([50.0, 50.0, 0.0], dtype=np.float32)
        
        entropies = [cell.entropy for cell in nearby_cells]
        return np.array([
            np.mean(entropies),
            np.max(entropies),
            np.std(entropies)
        ], dtype=np.float32)
    
    def _get_scan_info(self, grid_data):
        """è·å–æ‰«æè¿›åº¦ä¿¡æ¯"""
        if not grid_data or not grid_data.cells:
            return np.array([0.0, 0.0, 0.0], dtype=np.float32)
        
        total = len(grid_data.cells)
        scanned = sum(
            1 for cell in grid_data.cells
            if cell.entropy < self.config['thresholds']['scanned_entropy']
        )
        
        return np.array([
            scanned / max(total, 1),
            float(scanned),
            float(total - scanned)
        ], dtype=np.float32)
    
    def _count_scanned_cells(self):
        """ç»Ÿè®¡å·²æ‰«æå•å…ƒæ ¼æ•°é‡"""
        if not self.server or not self.server.grid_data:
            return 0
            
        try:
            with self.server.grid_lock:  # ä½¿ç”¨ grid_lock è€Œä¸æ˜¯ data_lock
                return sum(
                    1 for cell in self.server.grid_data.cells
                    if cell.entropy < self.config['thresholds']['scanned_entropy']
                )
        except:
            return 0
        
    def _get_total_entropy(self):
        """è·å–æ€»ç†™å€¼"""
        if not self.server or not self.server.grid_data:
            return 0.0
            
        try:
            with self.server.grid_lock:  # ä½¿ç”¨ grid_lock è€Œä¸æ˜¯ data_lock
                return sum(cell.entropy for cell in self.server.grid_data.cells)
        except:
            return 0.0
        
    def _get_scan_ratio(self):
        """è·å–æ‰«æå®Œæˆæ¯”ä¾‹"""
        if not self.server or not self.server.grid_data:
            return 0.0
            
        try:
            with self.server.grid_lock:  # ä½¿ç”¨ grid_lock è€Œä¸æ˜¯ data_lock
                total = len(self.server.grid_data.cells)
                if total == 0:
                    return 0.0
                scanned = sum(
                    1 for cell in self.server.grid_data.cells
                    if cell.entropy < self.config['thresholds']['scanned_entropy']
                )
                return scanned / total
        except:
            return 0.0
    
    def _get_min_distance_to_others(self, runtime_data):
        """è·å–åˆ°å…¶ä»–æ— äººæœºçš„æœ€å°è·ç¦»"""
        if not runtime_data.otherScannerPositions:
            return 999.0
        
        pos = runtime_data.position
        distances = [
            np.sqrt(
                (pos.x - other_pos.x) ** 2 +
                (pos.y - other_pos.y) ** 2 +
                (pos.z - other_pos.z) ** 2
            )
            for other_pos in runtime_data.otherScannerPositions
        ]
        return min(distances) if distances else 999.0
    
    def _get_battery_info(self):
        """è·å–ç”µé‡ä¿¡æ¯ï¼š[ç”µå‹, å‰©ä½™ç™¾åˆ†æ¯”]"""
        if not self.server or not hasattr(self.server, 'get_battery_voltage'):
            return np.array([4.2, 100.0], dtype=np.float32)  # é»˜è®¤å€¼ï¼šæ»¡ç”µ
        
        try:
            voltage = self.server.get_battery_voltage(self.drone_name)
            battery_info = self.server.battery_manager.get_battery_info(self.drone_name)
            if battery_info:
                percentage = battery_info.get_remaining_percentage()
                return np.array([voltage, percentage], dtype=np.float32)
            else:
                return np.array([voltage, 100.0], dtype=np.float32)
        except:
            return np.array([4.2, 100.0], dtype=np.float32)
    
    def render(self, mode='human'):
        """å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰"""
        pass
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        pass


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=" * 60)
    print("æµ‹è¯• MovementEnv - æ— äººæœºç§»åŠ¨DQNç¯å¢ƒ")
    print("=" * 60)
    
    # åˆ›å»ºç¯å¢ƒï¼ˆæ— serverï¼Œæµ‹è¯•æ¨¡å¼ï¼‰
    env = MovementEnv(server=None, drone_name="UAV1")
    
    print(f"\nè§‚å¯Ÿç©ºé—´: {env.observation_space}")
    print(f"åŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"åŠ¨ä½œæ˜ å°„:")
    for action, displacement in env.action_map.items():
        action_name = ['ä¸Š', 'ä¸‹', 'å·¦', 'å³', 'å‰', 'å'][action]
        print(f"  {action}: {action_name} -> {displacement}")
    
    # é‡ç½®ç¯å¢ƒ
    state, info = env.reset()
    print(f"\nåˆå§‹çŠ¶æ€shape: {state.shape}")
    print(f"åˆå§‹çŠ¶æ€å‰5ç»´: {state[:5]}")
    
    # æ‰§è¡Œå‡ æ­¥æµ‹è¯•
    print("\næ‰§è¡ŒåŠ¨ä½œæµ‹è¯•:")
    for i in range(6):
        action = i  # æµ‹è¯•æ‰€æœ‰6ä¸ªåŠ¨ä½œ
        action_name = ['ä¸Š', 'ä¸‹', 'å·¦', 'å³', 'å‰', 'å'][action]
        
        print(f"\næ­¥éª¤ {i+1}: åŠ¨ä½œ={action} ({action_name})")
        state, reward, done, info = env.step(action)
        print(f"  å¥–åŠ±: {reward:.2f}")
        print(f"  å®Œæˆ: {done}")
        print(f"  ä¿¡æ¯: {info}")
        
        if done:
            break
    
    print("\n" + "=" * 60)
    print("[OK] ç¯å¢ƒæµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)


class MultiDroneMovementEnv(gym.Env):
    """
    å¤šæ— äººæœºç§»åŠ¨å­¦ä¹ ç¯å¢ƒï¼ˆå‚æ•°å…±äº«ï¼‰
    
    å¤šä¸ªæ— äººæœºè½®æµæ‰§è¡ŒåŠ¨ä½œï¼Œå…±äº«åŒä¸€ä¸ª DQN æ¨¡å‹
    åŠ¨ä½œç©ºé—´: 6ä¸ªç¦»æ•£åŠ¨ä½œï¼ˆä¸Š/ä¸‹/å·¦/å³/å‰/åï¼‰
    è§‚å¯Ÿç©ºé—´: ä½ç½®ã€é€Ÿåº¦ã€ç†™å€¼ã€leaderä½ç½®ç­‰
    """
    
    def __init__(self, server=None, drone_names=None, config_path=None):
        super(MultiDroneMovementEnv, self).__init__()
        
        self.server = server
        self.drone_names = drone_names if drone_names else ["UAV1"]
        self.num_drones = len(self.drone_names)
        
        # å½“å‰æ§åˆ¶çš„æ— äººæœºç´¢å¼•ï¼ˆè½®æµæ§åˆ¶ï¼‰
        self.current_drone_idx = 0
        
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        print(f"[OK] å¤šæ— äººæœº DQN ç¯å¢ƒå·²åŠ è½½é…ç½®")
        print(f"  æ— äººæœºæ•°é‡: {self.num_drones}")
        print(f"  æ— äººæœºåˆ—è¡¨: {self.drone_names}")
        
        # åŠ¨ä½œç©ºé—´: 6ä¸ªç¦»æ•£åŠ¨ä½œï¼ˆæ‰€æœ‰æ— äººæœºå…±äº«ï¼‰
        self.action_space = spaces.Discrete(6)
        
        # è§‚å¯Ÿç©ºé—´: 23ç»´ï¼ˆæ‰€æœ‰æ— äººæœºå…±äº«ç›¸åŒç»“æ„ï¼‰
        self.observation_space = spaces.Box(
            low=-np.inf,
            high=np.inf,
            shape=(23,),
            dtype=np.float32
        )
        
        # åŠ¨ä½œåˆ°ä½ç§»çš„æ˜ å°„
        self.action_step = self.config['movement']['step_size']
        self.action_map = {
            0: np.array([0, 0, self.action_step]),      # ä¸Š
            1: np.array([0, 0, -self.action_step]),     # ä¸‹
            2: np.array([-self.action_step, 0, 0]),     # å·¦
            3: np.array([self.action_step, 0, 0]),      # å³
            4: np.array([0, self.action_step, 0]),      # å‰
            5: np.array([0, -self.action_step, 0])      # å
        }
        
        # ä¸ºæ¯ä¸ªæ— äººæœºç»´æŠ¤ç‹¬ç«‹çš„çŠ¶æ€è®°å½•
        self.drone_states = {}
        for drone_name in self.drone_names:
            self.drone_states[drone_name] = {
                'prev_scanned_cells': 0,
                'prev_position': None,
                'prev_entropy_sum': 0,
                'collision_count': 0,
                'out_of_range_count': 0,
                'episode_reward': 0
            }
        
        # å…¨å±€çŠ¶æ€
        self.step_count = 0
        self.total_episode_reward = 0
        self.episode_index = 0  # Episode è®¡æ•°å™¨ï¼ˆç”¨äº DataCollectorï¼‰
        
        # é¦–æ¬¡é‡ç½®æ ‡å¿—ï¼ˆç”¨äºè·³è¿‡å¯åŠ¨æ—¶çš„é‡ç½®ï¼‰
        self._first_reset = True
        
    def _load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            config_path = os.path.join(current_dir, "movement_dqn_config.json")
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return self._default_config()
    
    def _default_config(self):
        """é»˜è®¤é…ç½®"""
        return {
            "movement": {
                "step_size": 1.0,
                "max_steps": 500
            },
            "rewards": {
                "exploration": 10.0,
                "collision": -50.0,
                "out_of_range": -30.0,
                "smooth_movement": 1.0,
                "entropy_reduction": 5.0,
                "high_entropy_exploration": 5.0,
                "entropy_gradient_bonus": 2.0,
                "step_penalty": -0.1,
                "success": 100.0,
                "height_penalty": -5.0,
                "optimal_height_bonus": 1.0
            },
            "thresholds": {
                "collision_distance": 2.0,
                "scanned_entropy": 30.0,
                "nearby_entropy_distance": 10.0,
                "success_scan_ratio": 0.95,
                "high_entropy_threshold": 40.0,
                "min_scan_height": 2.0,
                "max_scan_height": 15.0,
                "optimal_scan_height": 8.0
            }
        }
    
    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒ"""
        print(f"[DQNå¤šæœºç¯å¢ƒ] reset() è¢«è°ƒç”¨")
        if seed is not None:
            np.random.seed(seed)
        
        # é¦–æ¬¡é‡ç½®ï¼šè·³è¿‡ç¯å¢ƒé‡ç½®ï¼ˆå› ä¸ºæ— äººæœºåˆšèµ·é£ï¼Œé¢†å¯¼è€…åˆšå¼€å§‹ç§»åŠ¨ï¼‰
        if self._first_reset:
            self._first_reset = False
            print(f"[DQNå¤šæœºç¯å¢ƒ] ğŸš€ é¦–æ¬¡resetï¼Œè·³è¿‡ç¯å¢ƒé‡ç½®ï¼Œç›´æ¥åˆå§‹åŒ–çŠ¶æ€")
            # ä»…é‡ç½®æ‰€æœ‰æ— äººæœºçš„ç”µé‡
            if self.server and hasattr(self.server, 'reset_battery_voltage'):
                for drone_name in self.drone_names:
                    self.server.reset_battery_voltage(drone_name)
        else:
            # åç»­é‡ç½®ï¼šæ‰§è¡Œå®Œæ•´çš„ç¯å¢ƒé‡ç½®ï¼ˆEpisodeç»“æŸï¼‰
            if self.server:
                print(f"[DQNå¤šæœºç¯å¢ƒ] ğŸ”„ Episodeç»“æŸï¼Œæ‰§è¡Œå®Œæ•´ç¯å¢ƒé‡ç½®...")
                self.server.reset_environment()
                # é‡ç½®æ‰€æœ‰æ— äººæœºçš„ç”µé‡
                if hasattr(self.server, 'reset_battery_voltage'):
                    for drone_name in self.drone_names:
                        self.server.reset_battery_voltage(drone_name)
                import time
                time.sleep(1.0)
                print(f"[DQNå¤šæœºç¯å¢ƒ] âœ… ç¯å¢ƒé‡ç½®å®Œæˆ")
        
        # é‡ç½®æ¯ä¸ªæ— äººæœºçš„çŠ¶æ€
        print(f"[DQNå¤šæœºç¯å¢ƒ] é‡ç½® {self.num_drones} ä¸ªæ— äººæœºçŠ¶æ€...")
        for drone_name in self.drone_names:
            self.drone_states[drone_name] = {
                'prev_scanned_cells': self._count_scanned_cells(),
                'prev_position': None,
                'prev_entropy_sum': self._get_total_entropy(),
                'collision_count': 0,
                'out_of_range_count': 0,
                'episode_reward': 0
            }
        
        self.step_count = 0
        self.total_episode_reward = 0
        self.current_drone_idx = 0
        
        # Episode è®¡æ•°å™¨é€’å¢
        self.episode_index += 1
        
        # è¿”å›ç¬¬ä¸€ä¸ªæ— äººæœºçš„çŠ¶æ€
        print(f"[DQNå¤šæœºç¯å¢ƒ] è·å–åˆå§‹çŠ¶æ€...")
        state = self._get_state(self.drone_names[0])
        print(f"[DQNå¤šæœºç¯å¢ƒ] reset() å®Œæˆï¼ŒçŠ¶æ€shape: {state.shape}")
        return state, {}
    
    def step(self, action):
        """
        æ‰§è¡Œä¸€æ­¥åŠ¨ä½œï¼ˆå½“å‰æ— äººæœºï¼‰
        
        :param action: 0-5çš„æ•´æ•°ï¼Œè¡¨ç¤º6ä¸ªç§»åŠ¨æ–¹å‘
        :return: observation, reward, terminated, truncated, info
        """
        print(f"[DQNå¤šæœºç¯å¢ƒ] step({action}) è¢«è°ƒç”¨")
        
        # ç¡®ä¿ action æ˜¯æ•´æ•°
        if hasattr(action, 'item'):
            action = action.item()
        action = int(action)
        
        # å½“å‰æ§åˆ¶çš„æ— äººæœº
        current_drone = self.drone_names[self.current_drone_idx]
        print(f"[DQNå¤šæœºç¯å¢ƒ] å½“å‰æ§åˆ¶æ— äººæœº: {current_drone}")
        
        # è·å–å½“å‰çŠ¶æ€
        print(f"[DQNå¤šæœºç¯å¢ƒ] è·å–å½“å‰çŠ¶æ€...")
        current_state = self._get_state(current_drone)
        print(f"[DQNå¤šæœºç¯å¢ƒ] å½“å‰çŠ¶æ€è·å–å®Œæˆ")
        
        # æ‰§è¡ŒåŠ¨ä½œ
        print(f"[DQNå¤šæœºç¯å¢ƒ] æ‰§è¡ŒåŠ¨ä½œ {action}...")
        displacement = self.action_map[action]
        if self.server:
            self._apply_movement(current_drone, displacement)
            import time
            time.sleep(0.05)
        print(f"[DQNå¤šæœºç¯å¢ƒ] åŠ¨ä½œæ‰§è¡Œå®Œæˆ")
        
        # è·å–æ–°çŠ¶æ€
        print(f"[DQNå¤šæœºç¯å¢ƒ] è·å–æ–°çŠ¶æ€...")
        next_state = self._get_state(current_drone)
        print(f"[DQNå¤šæœºç¯å¢ƒ] æ–°çŠ¶æ€è·å–å®Œæˆ")
        
        # è®¡ç®—å¥–åŠ±
        print(f"[DQNå¤šæœºç¯å¢ƒ] è®¡ç®—å¥–åŠ±...")
        reward = self._calculate_reward(current_drone, action, current_state, next_state)
        print(f"[DQNå¤šæœºç¯å¢ƒ] å¥–åŠ±è®¡ç®—å®Œæˆ: {reward:.2f}")
        
        self.drone_states[current_drone]['episode_reward'] += reward
        self.total_episode_reward += reward
        
        # æ›´æ–°è®¡æ•°å™¨
        self.step_count += 1
        
        # å°†è®­ç»ƒç»Ÿè®¡ä¿¡æ¯ä¼ é€’ç»™æœåŠ¡å™¨ï¼ˆç”¨äº DataCollectorï¼‰
        if self.server and hasattr(self.server, 'set_training_stats'):
            self.server.set_training_stats(
                episode=self.episode_index,
                step=self.step_count,
                reward=float(reward),
                total_reward=float(self.total_episode_reward)
            )
        
        # è½®æµåˆ°ä¸‹ä¸€ä¸ªæ— äººæœº
        self.current_drone_idx = (self.current_drone_idx + 1) % self.num_drones
        
        # åˆ¤æ–­æ˜¯å¦ç»“æŸ
        print(f"[DQNå¤šæœºç¯å¢ƒ] æ£€æŸ¥æ˜¯å¦ç»“æŸ...")
        terminated = self._check_done()
        print(f"[DQNå¤šæœºç¯å¢ƒ] ç»“æŸæ£€æŸ¥å®Œæˆ: {terminated}")
        truncated = False
        
        # é¢å¤–ä¿¡æ¯
        info = {
            'drone_name': current_drone,
            'action': action,
            'displacement': displacement.tolist(),
            'scanned_cells': self._count_scanned_cells(),
            'total_reward': self.total_episode_reward,
            'step_count': self.step_count,
            'current_drone_idx': self.current_drone_idx
        }
        
        # è¿”å›ä¸‹ä¸€ä¸ªæ— äººæœºçš„çŠ¶æ€
        next_drone = self.drone_names[self.current_drone_idx]
        print(f"[DQNå¤šæœºç¯å¢ƒ] è·å–ä¸‹ä¸€ä¸ªæ— äººæœºçŠ¶æ€: {next_drone}")
        next_observation = self._get_state(next_drone)
        print(f"[DQNå¤šæœºç¯å¢ƒ] step() å®Œæˆ")
        
        return next_observation, reward, terminated, truncated, info
    
    def _get_state(self, drone_name):
        """è·å–æŒ‡å®šæ— äººæœºçš„è§‚å¯ŸçŠ¶æ€ï¼ˆ21ç»´ï¼‰"""
        if not self.server:
            return np.random.randn(21).astype(np.float32)
        
        try:
            # åˆ†ç¦»é”çš„è·å–ï¼Œé¿å…æ­»é”
            # ç¬¬ä¸€æ­¥ï¼šä» runtime_data è·å–æ— äººæœºçŠ¶æ€
            with self.server.data_lock:
                runtime_data = self.server.unity_runtime_data.get(drone_name)
                if not runtime_data:
                    print(f"[DQNå¤šæœºç¯å¢ƒ] è­¦å‘Š: æ— äººæœº {drone_name} çš„runtime_dataä¸å­˜åœ¨")
                    return np.zeros(21, dtype=np.float32)
                
                # 1. ä½ç½® (3)
                pos = runtime_data.position
                position = np.array([pos.x, pos.y, pos.z], dtype=np.float32)
                
                # 2. é€Ÿåº¦ (3)
                vel = runtime_data.velocity
                velocity = np.array([vel.x, vel.y, vel.z], dtype=np.float32)
                
                # 3. æœå‘ (3)
                fwd = runtime_data.forward
                forward = np.array([fwd.x, fwd.y, fwd.z], dtype=np.float32)
                
                # 5. Leaderç›¸å¯¹ä½ç½® (3)
                if runtime_data.leader_position:
                    leader_rel = np.array([
                        runtime_data.leader_position.x - pos.x,
                        runtime_data.leader_position.y - pos.y,
                        runtime_data.leader_position.z - pos.z
                    ], dtype=np.float32)
                else:
                    leader_rel = np.array([0.0, 0.0, 0.0], dtype=np.float32)
                
                # 6. LeaderèŒƒå›´ä¿¡æ¯ (2)
                leader_distance = float(np.linalg.norm(leader_rel))
                is_out_of_range = 1.0 if leader_distance > runtime_data.leader_scan_radius else 0.0
                leader_info = np.array([leader_distance, is_out_of_range], dtype=np.float32)
            
            # ç¬¬äºŒæ­¥ï¼šä» grid_data è·å–ç½‘æ ¼ä¿¡æ¯
            with self.server.grid_lock:
                grid_data = self.server.grid_data
                if not grid_data or not grid_data.cells:
                    print(f"[DQNå¤šæœºç¯å¢ƒ] è­¦å‘Š: grid_data ä¸ºç©ºæˆ–æ²¡æœ‰cells")
                    # è¿”å›å¸¦æœ‰åŸºæœ¬ä¿¡æ¯çš„çŠ¶æ€
                    entropy_info = np.array([50.0, 50.0, 0.0], dtype=np.float32)
                    scan_info = np.array([0.0, 0.0, 0.0], dtype=np.float32)
                    min_dist_info = np.array([100.0], dtype=np.float32)
                else:
                    # 4. å±€éƒ¨ç†™å€¼ç»Ÿè®¡ (3)
                    nearby_distance = self.config['thresholds']['nearby_entropy_distance']
                    nearby_cells = [c for c in grid_data.cells if (c.center - pos).magnitude() < nearby_distance]
                    if nearby_cells:
                        entropies = [c.entropy for c in nearby_cells]
                        entropy_info = np.array([
                            float(np.mean(entropies)),
                            float(np.max(entropies)),
                            float(np.std(entropies))
                        ], dtype=np.float32)
                    else:
                        entropy_info = np.array([50.0, 50.0, 0.0], dtype=np.float32)
                    
                    # 7. æ‰«æè¿›åº¦ (3)
                    scanned_threshold = self.config['thresholds']['scanned_entropy']
                    scanned_count = sum(1 for cell in grid_data.cells if cell.entropy < scanned_threshold)
                    total_cells = len(grid_data.cells)
                    unscanned_count = total_cells - scanned_count
                    scan_ratio = scanned_count / total_cells if total_cells > 0 else 0.0
                    scan_info = np.array([scan_ratio, float(scanned_count), float(unscanned_count)], dtype=np.float32)
                    
                    # 8. å…¶ä»–æ— äººæœºæœ€è¿‘è·ç¦» (1) - éœ€è¦é‡æ–°è·å– data_lock
                    min_dist_info = np.array([100.0], dtype=np.float32)  # é»˜è®¤å€¼
            
            # ç¬¬ä¸‰æ­¥ï¼šè·å–å…¶ä»–æ— äººæœºè·ç¦»
            min_distance = self._get_min_distance_to_others(drone_name)
            min_dist_info = np.array([min_distance], dtype=np.float32)
            
            # ç¬¬å››æ­¥ï¼šè·å–ç”µé‡ä¿¡æ¯
            battery_info = self._get_battery_info_for_drone(drone_name)
            
            # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
            state = np.concatenate([
                position,
                velocity,
                forward,
                entropy_info,
                leader_rel,
                leader_info,
                scan_info,
                min_dist_info,
                battery_info
            ])
            
            return state.astype(np.float32)
            
        except Exception as e:
            logger.error(f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return np.zeros(23, dtype=np.float32)
    
    def _get_min_distance_to_others(self, drone_name):
        """è·å–åˆ°å…¶ä»–æ— äººæœºçš„æœ€å°è·ç¦»"""
        try:
            with self.server.data_lock:
                current_pos = self.server.unity_runtime_data[drone_name].position
                min_distance = float('inf')
                
                for other_drone in self.drone_names:
                    if other_drone != drone_name:
                        other_pos = self.server.unity_runtime_data[other_drone].position
                        distance = (current_pos - other_pos).magnitude()
                        min_distance = min(min_distance, distance)
                
                return min_distance if min_distance != float('inf') else 100.0
        except:
            return 100.0
    
    def _get_battery_info_for_drone(self, drone_name):
        """è·å–æŒ‡å®šæ— äººæœºçš„ç”µé‡ä¿¡æ¯ï¼š[ç”µå‹, å‰©ä½™ç™¾åˆ†æ¯”]"""
        if not self.server or not hasattr(self.server, 'get_battery_voltage'):
            return np.array([4.2, 100.0], dtype=np.float32)  # é»˜è®¤å€¼ï¼šæ»¡ç”µ
        
        try:
            voltage = self.server.get_battery_voltage(drone_name)
            battery_info = self.server.battery_manager.get_battery_info(drone_name)
            if battery_info:
                percentage = battery_info.get_remaining_percentage()
                return np.array([voltage, percentage], dtype=np.float32)
            else:
                return np.array([voltage, 100.0], dtype=np.float32)
        except:
            return np.array([4.2, 100.0], dtype=np.float32)
    
    def _apply_movement(self, drone_name, displacement):
        """åº”ç”¨ç§»åŠ¨åˆ°æ— äººæœºï¼ˆé€šè¿‡AlgorithmServerçš„DQNæ§åˆ¶æ¨¡å¼ï¼‰"""
        if not self.server:
            return
        
        try:
            if not hasattr(self.server, 'control_mode') or self.server.control_mode != 'dqn':
                logger.warning("è­¦å‘Š: AlgorithmServeræœªå¤„äºDQNæ§åˆ¶æ¨¡å¼")
                return
            
            from Algorithm.Vector3 import Vector3
            magnitude = np.linalg.norm(displacement)
            if magnitude > 1e-6:
                direction = displacement / magnitude
                move_direction = Vector3(direction[0], direction[1], direction[2])
            else:
                move_direction = Vector3(0, 0, 0)
            
            self.server.set_dqn_movement(drone_name, move_direction)
            
        except Exception as e:
            logger.error(f"åº”ç”¨ç§»åŠ¨å¤±è´¥: {str(e)}")
    
    def _calculate_reward(self, drone_name, action, current_state, next_state):
        """è®¡ç®—å¥–åŠ±"""
        reward = 0.0
        drone_state = self.drone_states[drone_name]
        
        # 0. è®¡ç®—ç¨³å®šæ€§ç³»æ•° (åŸºäºåˆ° Leader çš„è·ç¦»)
        stability_factor = 1.0
        dist_to_leader = next_state[15]  # è§‚å¯ŸçŠ¶æ€ä¸­çš„ Leader è·ç¦»
        is_out_of_range = next_state[16] > 0.5
        
        cfg_reward = self.config['rewards']
        cfg_thresh = self.config['thresholds']
        
        try:
            with self.server.data_lock:
                runtime_data = self.server.unity_runtime_data[drone_name]
                radius = runtime_data.leader_scan_radius
                if radius > 0:
                    dist_ratio = dist_to_leader / radius
                    
                    # ä»é…ç½®è·å–æ¯”ä¾‹
                    safe_ratio = cfg_thresh.get('stability_safe_ratio', 0.7)
                    penalty_ratio = cfg_thresh.get('stability_penalty_ratio', 0.8)
                    
                    if dist_ratio > 1.0:
                        stability_factor = 0.0
                    elif dist_ratio > safe_ratio:
                        # safe_ratio - 1.0 ä¹‹é—´çº¿æ€§è¡°å‡
                        stability_factor = 1.0 - (dist_ratio - safe_ratio) / (1.0 - safe_ratio) * 0.9
                    
                    # é¢å¤–ç¨³å®šæ€§æƒ©ç½š
                    if dist_ratio > penalty_ratio:
                        penalty_weight = cfg_reward.get('stability_penalty_weight', 20.0)
                        reward -= (dist_ratio - penalty_ratio) * penalty_weight
        except:
            pass
            
        # 1. æ¢ç´¢å¥–åŠ± (å—ç¨³å®šæ€§ç³»æ•°å½±å“)
        current_scanned = self._count_scanned_cells()
        new_cells = current_scanned - drone_state['prev_scanned_cells']
        if new_cells > 0:
            reward += new_cells * cfg_reward['exploration'] * stability_factor
        drone_state['prev_scanned_cells'] = current_scanned
            
        # 2. ç†µå€¼é™ä½å¥–åŠ± (å—ç¨³å®šæ€§ç³»æ•°å½±å“)
        current_entropy = self._get_total_entropy()
        entropy_reduction = drone_state['prev_entropy_sum'] - current_entropy
        if entropy_reduction > 0:
            reward += entropy_reduction * cfg_reward['entropy_reduction'] * 0.01 * stability_factor
        drone_state['prev_entropy_sum'] = current_entropy
            
        # 3. ã€ä¼˜åŒ–ã€‘å±€éƒ¨é«˜ç†µæ¢ç´¢å¥–åŠ±
        # ä¿®æ­£ç´¢å¼•ï¼š9-å¹³å‡ç†µ, 10-æœ€å¤§ç†µ
        local_avg_entropy = next_state[9]
        local_max_entropy = next_state[10]
            
        if local_max_entropy > cfg_thresh.get('high_entropy_threshold', 40.0):
            entropy_exploration_bonus = cfg_reward.get('high_entropy_exploration', 5.0)
            reward += entropy_exploration_bonus * stability_factor
            
        if drone_state['prev_position']:
            prev_local_avg_entropy = current_state[9]
            entropy_increase = local_avg_entropy - prev_local_avg_entropy
            if entropy_increase > 0:
                entropy_gradient_reward = entropy_increase * cfg_reward.get('entropy_gradient_bonus', 2.0)
                reward += entropy_gradient_reward * stability_factor
            
        # 4. ã€æ–°å¢ã€‘é«˜åº¦æ§åˆ¶å¥–åŠ±/æƒ©ç½š
        try:
            with self.server.data_lock:
                runtime_data = self.server.unity_runtime_data[drone_name]
                pos = runtime_data.position
                current_height = pos.z
                    
                min_scan_height = cfg_thresh.get('min_scan_height', 2.0)
                max_scan_height = cfg_thresh.get('max_scan_height', 15.0)
                optimal_height = cfg_thresh.get('optimal_scan_height', 8.0)
                    
                if current_height < min_scan_height:
                    reward += cfg_reward.get('height_penalty', -5.0)
                elif current_height > max_scan_height:
                    reward += cfg_reward.get('height_penalty', -5.0)
                elif abs(current_height - optimal_height) < 2.0:
                    reward += cfg_reward.get('optimal_height_bonus', 1.0)
                    
                drone_state['prev_position'] = pos
        except Exception as e:
            logger.debug(f"é«˜åº¦å¥–åŠ±è®¡ç®—å¤±è´¥: {str(e)}")
            
        # 5. ç¢°æ’æƒ©ç½š
        min_distance = self._get_min_distance_to_others(drone_name)
        if min_distance < cfg_thresh['collision_distance']:
            reward += cfg_reward['collision']
            drone_state['collision_count'] += 1
        
        # 6. è¶…å‡ºLeaderèŒƒå›´æƒ©ç½š
        if is_out_of_range:
            reward += cfg_reward['out_of_range']
            drone_state['out_of_range_count'] += 1
        
        # 7. æ­¥éª¤æƒ©ç½š
        reward += cfg_reward['step_penalty']
        
        # 8. ç”µé‡å¥–åŠ±ä¸æƒ©ç½š
        if self.server and hasattr(self.server, 'get_battery_voltage'):
            try:
                current_voltage = self.server.get_battery_voltage(drone_name)
                battery_info = self.server.battery_manager.get_battery_info(drone_name)
                if battery_info:
                    # ç”µé‡è¿‡ä½æƒ©ç½š
                    if 'battery_low_threshold' in cfg_thresh:
                        if current_voltage < cfg_thresh['battery_low_threshold']:
                            penalty = cfg_reward.get('battery_low_penalty', 10.0)
                            reward -= penalty
                    
                    # ç”µé‡æœ€ä¼˜èŒƒå›´å¥–åŠ±
                    if 'battery_optimal_min' in cfg_thresh and 'battery_optimal_max' in cfg_thresh:
                        opt_min = cfg_thresh['battery_optimal_min']
                        opt_max = cfg_thresh['battery_optimal_max']
                        if opt_min <= current_voltage <= opt_max:
                            bonus = cfg_reward.get('battery_optimal_reward', 2.0)
                            reward += bonus
                
                # æ›´æ–°ç”µé‡æ¶ˆè€—
                if hasattr(self.server, 'update_battery_voltage'):
                    action_intensity = 0.5
                    self.server.update_battery_voltage(drone_name, action_intensity)
            except Exception as e:
                logger.debug(f"ç”µé‡å¥–åŠ±è®¡ç®—å¤±è´¥: {str(e)}")
        
        return reward
    
    def _check_done(self):
        """æ£€æŸ¥episodeæ˜¯å¦ç»“æŸ"""
        # è¶…è¿‡æœ€å¤§æ­¥æ•°
        max_steps = self.config['movement']['max_steps'] * self.num_drones
        if self.step_count >= max_steps:
            return True
        
        # æ‰«æå®Œæˆ
        scan_ratio = self._get_scan_ratio()
        if scan_ratio >= self.config['thresholds']['success_scan_ratio']:
            return True
        
        return False
    
    def _count_scanned_cells(self):
        """ç»Ÿè®¡å·²æ‰«æå•å…ƒæ ¼æ•°é‡"""
        if not self.server:
            return 0
        try:
            with self.server.grid_lock:
                scanned_threshold = self.config['thresholds']['scanned_entropy']
                return sum(1 for cell in self.server.grid_data.cells if cell.entropy < scanned_threshold)
        except:
            return 0
    
    def _get_total_entropy(self):
        """è·å–æ€»ç†™å€¼"""
        if not self.server:
            return 0.0
        try:
            with self.server.grid_lock:
                return sum(cell.entropy for cell in self.server.grid_data.cells)
        except:
            return 0.0
    
    def _get_scan_ratio(self):
        """è·å–æ‰«ææ¯”ä¾‹"""
        if not self.server:
            return 0.0
        try:
            with self.server.grid_lock:
                total = len(self.server.grid_data.cells)
                if total == 0:
                    return 0.0
                # ç›´æ¥åœ¨è¿™é‡Œè®¡ç®—ï¼Œè€Œä¸æ˜¯è°ƒç”¨ _count_scanned_cells()ï¼ˆé¿å…é‡å¤è·å–é”ï¼‰
                scanned_threshold = self.config['thresholds']['scanned_entropy']
                scanned = sum(1 for cell in self.server.grid_data.cells if cell.entropy < scanned_threshold)
                return scanned / total
        except:
            return 0.0
