"""
æµ‹è¯•DQNç§»åŠ¨æ¨¡å‹
åŠ è½½è®­ç»ƒå¥½çš„DQNæ¨¡å‹å¹¶æµ‹è¯•æ— äººæœºç§»åŠ¨ç­–ç•¥
"""
import os
import sys
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

print("=" * 80)
print("æµ‹è¯•DQNç§»åŠ¨æ¨¡å‹")
print("=" * 80)

# æ£€æŸ¥ä¾èµ–
print("\n[æ­¥éª¤1] æ£€æŸ¥ä¾èµ–...")
try:
    from stable_baselines3 import DQN
    import gymnasium
    print(f"  âœ“ Stable-Baselines3å·²å®‰è£…")
except ImportError:
    print("  âœ— Stable-Baselines3æœªå®‰è£…")
    print("    å®‰è£…å‘½ä»¤: pip install stable-baselines3 gymnasium")
    sys.exit(1)

# å¯¼å…¥ç¯å¢ƒ
from movement_env import MovementEnv

print("\n" + "=" * 80)
print("[æ­¥éª¤2] åŠ è½½æ¨¡å‹")
print("=" * 80)

# æ¨¡å‹è·¯å¾„
model_dir = os.path.join(os.path.dirname(__file__), 'models')
model_files = [
    'movement_dqn_final.zip',
    'movement_dqn_checkpoint_100000_steps.zip',
    'movement_dqn_checkpoint_50000_steps.zip'
]

# æŸ¥æ‰¾å¯ç”¨æ¨¡å‹
model_path = None
for model_file in model_files:
    test_path = os.path.join(model_dir, model_file)
    if os.path.exists(test_path):
        model_path = test_path
        break

if model_path is None:
    print("  âœ— æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
    print(f"  è¯·å…ˆè¿è¡Œè®­ç»ƒ: python train_movement_dqn.py")
    print(f"  é¢„æœŸæ¨¡å‹ä½ç½®: {model_dir}")
    sys.exit(1)

print(f"  âœ“ æ‰¾åˆ°æ¨¡å‹: {model_path}")

# åŠ è½½æ¨¡å‹
try:
    model = DQN.load(model_path)
    print(f"  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"  âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
    sys.exit(1)

print("\n" + "=" * 80)
print("[æ­¥éª¤3] åˆ›å»ºæµ‹è¯•ç¯å¢ƒ")
print("=" * 80)

# åˆ›å»ºç¯å¢ƒï¼ˆæ— serverï¼Œæµ‹è¯•æ¨¡å¼ï¼‰
env = MovementEnv(server=None, drone_name="UAV1")
print(f"  âœ“ æµ‹è¯•ç¯å¢ƒåˆ›å»ºæˆåŠŸ")

print("\n" + "=" * 80)
print("[æ­¥éª¤4] è¿è¡Œæµ‹è¯•Episodes")
print("=" * 80)

n_test_episodes = 5
print(f"æµ‹è¯•episodesæ•°é‡: {n_test_episodes}")
print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# ç»Ÿè®¡ä¿¡æ¯
episode_rewards = []
episode_lengths = []
episode_scanned = []

action_names = ['ä¸Š', 'ä¸‹', 'å·¦', 'å³', 'å‰', 'å']

for episode in range(n_test_episodes):
    print(f"\n{'=' * 60}")
    print(f"Episode {episode + 1}/{n_test_episodes}")
    print(f"{'=' * 60}")
    
    obs, info = env.reset()
    done = False
    episode_reward = 0
    episode_length = 0
    actions_taken = {i: 0 for i in range(6)}
    
    while not done:
        # ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥
        action, _states = model.predict(obs, deterministic=True)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated
        
        # ç»Ÿè®¡
        episode_reward += reward
        episode_length += 1
        actions_taken[action] += 1
        
        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯ï¼ˆæ¯10æ­¥æˆ–æœ€åä¸€æ­¥ï¼‰
        if episode_length % 10 == 0 or done:
            print(f"  æ­¥éª¤ {episode_length}: åŠ¨ä½œ={action_names[action]}, "
                  f"å¥–åŠ±={reward:.2f}, ç´¯è®¡å¥–åŠ±={episode_reward:.2f}, "
                  f"å·²æ‰«æ={info['scanned_cells']}")
        
        # é˜²æ­¢æ— é™å¾ªç¯
        if episode_length >= 1000:
            print(f"  âš  è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶ï¼Œå¼ºåˆ¶ç»“æŸ")
            break
    
    # Episodeç»Ÿè®¡
    episode_rewards.append(episode_reward)
    episode_lengths.append(episode_length)
    episode_scanned.append(info['scanned_cells'])
    
    print(f"\nEpisode {episode + 1} ç»“æœ:")
    print(f"  æ€»å¥–åŠ±: {episode_reward:.2f}")
    print(f"  æ€»æ­¥æ•°: {episode_length}")
    print(f"  å·²æ‰«æå•å…ƒæ ¼: {info['scanned_cells']}")
    print(f"  ç¢°æ’æ¬¡æ•°: {info['collision_count']}")
    print(f"  è¶Šç•Œæ¬¡æ•°: {info['out_of_range_count']}")
    print(f"  åŠ¨ä½œåˆ†å¸ƒ:")
    for action, count in actions_taken.items():
        percentage = (count / episode_length * 100) if episode_length > 0 else 0
        print(f"    {action_names[action]}: {count}æ¬¡ ({percentage:.1f}%)")

print("\n" + "=" * 80)
print("æµ‹è¯•æ€»ç»“")
print("=" * 80)

print(f"\nå¹³å‡ç»Ÿè®¡ ({n_test_episodes} episodes):")
print(f"  å¹³å‡å¥–åŠ±: {np.mean(episode_rewards):.2f} Â± {np.std(episode_rewards):.2f}")
print(f"  å¹³å‡æ­¥æ•°: {np.mean(episode_lengths):.1f} Â± {np.std(episode_lengths):.1f}")
print(f"  å¹³å‡æ‰«æ: {np.mean(episode_scanned):.1f} Â± {np.std(episode_scanned):.1f}")

print(f"\nè¯¦ç»†ç»“æœ:")
for i in range(n_test_episodes):
    print(f"  Episode {i+1}: å¥–åŠ±={episode_rewards[i]:.2f}, "
          f"æ­¥æ•°={episode_lengths[i]}, æ‰«æ={episode_scanned[i]}")

print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

print("\n" + "=" * 80)
print("âœ“ æµ‹è¯•å®Œæˆ")
print("=" * 80)

# æ€§èƒ½è¯„ä¼°
avg_reward = np.mean(episode_rewards)
print(f"\næ€§èƒ½è¯„ä¼°:")
if avg_reward > 100:
    print(f"  ğŸŒŸ ä¼˜ç§€ï¼å¹³å‡å¥–åŠ± {avg_reward:.2f} > 100")
elif avg_reward > 0:
    print(f"  âœ“ è‰¯å¥½ã€‚å¹³å‡å¥–åŠ± {avg_reward:.2f} > 0")
elif avg_reward > -100:
    print(f"  âš  ä¸€èˆ¬ã€‚å¹³å‡å¥–åŠ± {avg_reward:.2f}ï¼Œæ¨¡å‹å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ")
else:
    print(f"  âœ— è¾ƒå·®ã€‚å¹³å‡å¥–åŠ± {avg_reward:.2f}ï¼Œå»ºè®®é‡æ–°è®­ç»ƒ")

print("\nä¸‹ä¸€æ­¥:")
print(f"  1. æŸ¥çœ‹æ›´å¤šæµ‹è¯•: ä¿®æ”¹ n_test_episodes å˜é‡")
print(f"  2. å¯è§†åŒ–æµ‹è¯•: æ·»åŠ å¯è§†åŒ–ä»£ç ")
print(f"  3. ä¸AirSimé›†æˆ: ä½¿ç”¨çœŸå®ç¯å¢ƒæµ‹è¯•")
print("=" * 80)

