# DQNæ— äººæœºç§»åŠ¨æ§åˆ¶æ¨¡å—

## ğŸ“‹ æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æ·±åº¦Qç½‘ç»œ(DQN)è®­ç»ƒæ— äººæœºè¿›è¡Œè‡ªä¸»ç§»åŠ¨å’ŒåŒºåŸŸæ‰«æçš„æ¨¡å—ã€‚ä¸ä¼ ç»Ÿçš„æƒé‡å­¦ä¹ ä¸åŒï¼Œè¿™ä¸ªæ¨¡å—ç›´æ¥å­¦ä¹ æ— äººæœºçš„ç§»åŠ¨ç­–ç•¥ï¼Œé€šè¿‡6ä¸ªæ–¹å‘çš„ç¦»æ•£åŠ¨ä½œæ§åˆ¶æ— äººæœºã€‚

## ğŸ¯ åŠŸèƒ½ç‰¹ç‚¹

- **ç¦»æ•£åŠ¨ä½œç©ºé—´**: 6ä¸ªæ–¹å‘ç§»åŠ¨ï¼ˆä¸Š/ä¸‹/å·¦/å³/å‰/åï¼‰
- **ä¸°å¯Œçš„è§‚å¯Ÿç©ºé—´**: åŒ…å«ä½ç½®ã€é€Ÿåº¦ã€ç†µå€¼ã€Leaderä¿¡æ¯ç­‰21ç»´çŠ¶æ€
- **çµæ´»çš„å¥–åŠ±æœºåˆ¶**: æ¢ç´¢å¥–åŠ±ã€ç¢°æ’æƒ©ç½šã€è¶Šç•Œæƒ©ç½šç­‰å¤šç§å¥–åŠ±è®¾è®¡
- **æ”¯æŒçº¯æ¨¡æ‹Ÿè®­ç»ƒ**: å¯åœ¨æ— AirSimç¯å¢ƒä¸‹å¿«é€Ÿæµ‹è¯•å’ŒéªŒè¯
- **æ”¯æŒAirSimé›†æˆ**: å¯è¿æ¥çœŸå®Unityç¯å¢ƒè¿›è¡Œè®­ç»ƒ

## ğŸ“ æ–‡ä»¶ç»“æ„

```
DQN/
â”œâ”€â”€ movement_env.py                    # æ— äººæœºç§»åŠ¨ç¯å¢ƒç±»
â”œâ”€â”€ movement_dqn_config.json          # é…ç½®æ–‡ä»¶ï¼ˆå¥–åŠ±ã€é˜ˆå€¼ã€è®­ç»ƒå‚æ•°ï¼‰
â”œâ”€â”€ train_movement_dqn.py             # çº¯æ¨¡æ‹Ÿè®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_movement_with_airsim.py    # AirSimé›†æˆè®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_movement_dqn.py              # æ¨¡å‹æµ‹è¯•è„šæœ¬
â”œâ”€â”€ MOVEMENT_DQN.md                   # æœ¬æ–‡æ¡£
â””â”€â”€ models/                           # è®­ç»ƒæ¨¡å‹ä¿å­˜ç›®å½•
    â”œâ”€â”€ movement_dqn_final.zip
    â””â”€â”€ movement_dqn_checkpoint_*.zip
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®‰è£…å¿…è¦çš„ä¾èµ–ï¼š

```bash
pip install torch stable-baselines3 numpy gym
```

### 2. çº¯æ¨¡æ‹Ÿè®­ç»ƒï¼ˆæ¨èå…¥é—¨ï¼‰

ç›´æ¥åœ¨æœ¬åœ°è®­ç»ƒï¼Œæ— éœ€å¯åŠ¨Unityï¼š

```bash
# Windows
train_movement_dqn.bat

# æˆ–è€…ç›´æ¥è¿è¡ŒPython
python multirotor/DQN/train_movement_dqn.py
```

**ä¼˜ç‚¹**:
- âš¡ å¿«é€Ÿå¯åŠ¨ï¼Œæ— éœ€Unityç¯å¢ƒ
- ğŸ”„ é€‚åˆå¿«é€Ÿè¿­ä»£å’Œå‚æ•°è°ƒè¯•
- ğŸ’» èµ„æºå ç”¨å°

**ç¼ºç‚¹**:
- ğŸ¤– ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œä¸çœŸå®ç¯å¢ƒæœ‰å·®å¼‚

### 3. AirSimé›†æˆè®­ç»ƒï¼ˆçœŸå®ç¯å¢ƒï¼‰

è¿æ¥Unity AirSimç¯å¢ƒè¿›è¡Œè®­ç»ƒï¼š

```bash
# 1. å…ˆå¯åŠ¨Unityå®¢æˆ·ç«¯
# 2. è¿è¡Œè®­ç»ƒè„šæœ¬
train_movement_with_airsim.bat

# æˆ–è€…
python multirotor/DQN/train_movement_with_airsim.py
```

**ä¼˜ç‚¹**:
- ğŸ® çœŸå®ç¯å¢ƒåé¦ˆ
- ğŸ¯ æ›´å‡†ç¡®çš„æ¨¡å‹æ€§èƒ½
- ğŸ”— ç›´æ¥åº”ç”¨åˆ°å®é™…ä»»åŠ¡

**ç¼ºç‚¹**:
- â±ï¸ è®­ç»ƒé€Ÿåº¦è¾ƒæ…¢
- ğŸ–¥ï¸ éœ€è¦Unityç¯å¢ƒæ”¯æŒ

### 4. æµ‹è¯•æ¨¡å‹

è®­ç»ƒå®Œæˆåæµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼š

```bash
# Windows
test_movement_dqn.bat

# æˆ–è€…
python multirotor/DQN/test_movement_dqn.py
```

## âš™ï¸ é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ `movement_dqn_config.json` åŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š

### ç§»åŠ¨å‚æ•° (movement)

```json
{
  "step_size": 1.0,        // æ¯æ­¥ç§»åŠ¨è·ç¦»ï¼ˆç±³ï¼‰
  "max_steps": 500         // æ¯ä¸ªepisodeæœ€å¤§æ­¥æ•°
}
```

### å¥–åŠ±è®¾è®¡ (rewards)

```json
{
  "exploration": 10.0,          // å‘ç°æ–°åŒºåŸŸå¥–åŠ±
  "entropy_reduction": 5.0,     // é™ä½ç†µå€¼å¥–åŠ±
  "collision": -50.0,           // ç¢°æ’æƒ©ç½š
  "out_of_range": -30.0,        // è¶Šç•Œæƒ©ç½š
  "smooth_movement": 1.0,       // å¹³æ»‘ç§»åŠ¨å¥–åŠ±
  "step_penalty": -0.1,         // æ¯æ­¥å°æƒ©ç½š
  "success": 100.0              // å®Œæˆä»»åŠ¡å¤§å¥–åŠ±
}
```

### é˜ˆå€¼è®¾ç½® (thresholds)

```json
{
  "collision_distance": 2.0,          // ç¢°æ’åˆ¤å®šè·ç¦»ï¼ˆç±³ï¼‰
  "scanned_entropy": 30.0,            // å·²æ‰«æåˆ¤å®šé˜ˆå€¼
  "nearby_entropy_distance": 10.0,    // å±€éƒ¨ç†µå€¼ç»Ÿè®¡èŒƒå›´ï¼ˆç±³ï¼‰
  "success_scan_ratio": 0.95          // ä»»åŠ¡æˆåŠŸæ¯”ä¾‹
}
```

### è®­ç»ƒå‚æ•° (training)

```json
{
  "total_timesteps": 100000,           // è®­ç»ƒæ€»æ­¥æ•°
  "learning_rate": 0.0001,            // å­¦ä¹ ç‡
  "buffer_size": 50000,               // ç»éªŒå›æ”¾ç¼“å†²åŒº
  "batch_size": 32,                   // æ‰¹æ¬¡å¤§å°
  "gamma": 0.99,                      // æŠ˜æ‰£å› å­
  "exploration_fraction": 0.3,        // æ¢ç´¢è¡°å‡æ¯”ä¾‹
  "exploration_initial_eps": 1.0,     // åˆå§‹æ¢ç´¢ç‡
  "exploration_final_eps": 0.05       // æœ€ç»ˆæ¢ç´¢ç‡
}
```

## ğŸ“Š çŠ¶æ€ç©ºé—´è¯¦è§£

ç¯å¢ƒè§‚å¯Ÿç©ºé—´ä¸º21ç»´å‘é‡ï¼š

| ç»´åº¦èŒƒå›´ | åç§° | è¯´æ˜ |
|---------|------|------|
| 0-2 | ä½ç½® | x, y, zåæ ‡ |
| 3-5 | é€Ÿåº¦ | vx, vy, vzé€Ÿåº¦åˆ†é‡ |
| 6-8 | æœå‘ | forwardå‘é‡ |
| 9-11 | å±€éƒ¨ç†µå€¼ | å¹³å‡ç†µã€æœ€å¤§ç†µã€ç†µæ ‡å‡†å·® |
| 12-14 | Leaderç›¸å¯¹ä½ç½® | dx, dy, dz |
| 15-16 | LeaderèŒƒå›´ä¿¡æ¯ | è·ç¦»ã€æ˜¯å¦è¶Šç•Œ |
| 17-19 | æ‰«æè¿›åº¦ | å·²æ‰«ææ¯”ä¾‹ã€æ•°é‡ã€å‰©ä½™ |
| 20 | æœ€è¿‘æ— äººæœºè·ç¦» | é¿éšœç”¨ |

## ğŸ® åŠ¨ä½œç©ºé—´è¯¦è§£

6ä¸ªç¦»æ•£åŠ¨ä½œï¼š

| åŠ¨ä½œID | æ–¹å‘ | ä½ç§»å‘é‡ |
|--------|------|---------|
| 0 | ä¸Š | (0, 0, +step_size) |
| 1 | ä¸‹ | (0, 0, -step_size) |
| 2 | å·¦ | (-step_size, 0, 0) |
| 3 | å³ | (+step_size, 0, 0) |
| 4 | å‰ | (0, +step_size, 0) |
| 5 | å | (0, -step_size, 0) |

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### ä½¿ç”¨TensorboardæŸ¥çœ‹è®­ç»ƒæ›²çº¿

```bash
# çº¯æ¨¡æ‹Ÿè®­ç»ƒæ—¥å¿—
tensorboard --logdir=multirotor/DQN/logs/movement_dqn/

# AirSimé›†æˆè®­ç»ƒæ—¥å¿—
tensorboard --logdir=multirotor/DQN/logs/movement_dqn_airsim/
```

### å…³é”®æŒ‡æ ‡

- **ep_rew_mean**: å¹³å‡episodeå¥–åŠ±ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- **ep_len_mean**: å¹³å‡episodeé•¿åº¦ï¼ˆå¤ªé•¿è¯´æ˜æ•ˆç‡ä½ï¼‰
- **exploration_rate**: æ¢ç´¢ç‡ï¼ˆé€æ¸è¡°å‡åˆ°0.05ï¼‰
- **loss**: è®­ç»ƒæŸå¤±ï¼ˆåº”è¯¥é€æ¸ä¸‹é™ï¼‰

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: 
- ä½¿ç”¨GPU: ç¡®ä¿å®‰è£…äº†PyTorch GPUç‰ˆæœ¬
- å‡å°‘è®­ç»ƒæ­¥æ•°: ä¿®æ”¹ `total_timesteps`
- å¢å¤§æ‰¹æ¬¡: ä¿®æ”¹ `batch_size` (éœ€è¦æ›´å¤šå†…å­˜)
- ä½¿ç”¨çº¯æ¨¡æ‹Ÿæ¨¡å¼: ä¸è¿æ¥Unity

### Q2: æ¨¡å‹æ€§èƒ½ä¸å¥½ï¼Ÿ

**A**:
- è°ƒæ•´å¥–åŠ±æƒé‡: å¢åŠ æ¢ç´¢å¥–åŠ±ï¼Œå‡å°‘æƒ©ç½š
- å¢åŠ è®­ç»ƒæ—¶é—´: æé«˜ `total_timesteps`
- è°ƒæ•´æ¢ç´¢ç‡: å»¶é•¿æ¢ç´¢æ—¶é—´ `exploration_fraction`
- æ£€æŸ¥æ•°æ®: ç¡®ä¿ç¯å¢ƒçŠ¶æ€æ­£ç¡®

### Q3: å¦‚ä½•ç»§ç»­è®­ç»ƒå·²æœ‰æ¨¡å‹ï¼Ÿ

**A**:
```python
# åœ¨ train_movement_with_airsim.py ä¸­ä¼šè‡ªåŠ¨æ£€æµ‹
# ä¹Ÿå¯ä»¥æ‰‹åŠ¨åŠ è½½
model = DQN.load("models/movement_dqn_final.zip", env=env)
model.learn(total_timesteps=50000)  # ç»§ç»­è®­ç»ƒ
```

### Q4: å¦‚ä½•è°ƒæ•´ç§»åŠ¨æ­¥é•¿ï¼Ÿ

**A**:
ä¿®æ”¹ `movement_dqn_config.json` ä¸­çš„ `step_size`:
```json
{
  "movement": {
    "step_size": 2.0  // æ”¹ä¸º2ç±³/æ­¥
  }
}
```

## ğŸ“ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

ç¼–è¾‘ `movement_env.py` ä¸­çš„ `_calculate_reward` æ–¹æ³•ï¼š

```python
def _calculate_reward(self, action, prev_state, next_state):
    reward = 0.0
    
    # æ·»åŠ è‡ªå®šä¹‰å¥–åŠ±
    # ä¾‹å¦‚ï¼šé¼“åŠ±å‘é«˜ç†µåŒºåŸŸç§»åŠ¨
    entropy_diff = next_state[9] - prev_state[9]  # ç¬¬9ç»´æ˜¯å¹³å‡ç†µ
    if entropy_diff > 0:
        reward += 2.0  # ç§»å‘é«˜ç†µåŒºåŸŸ
    
    # ... å…¶ä»–å¥–åŠ±è®¡ç®—
    return reward
```

### ä½¿ç”¨ä¸åŒçš„DQNå˜ä½“

Stable-Baselines3æ”¯æŒå¤šç§DQNå˜ä½“ï¼š

```python
from stable_baselines3 import DQN  # æ ‡å‡†DQN
# from stable_baselines3 import DoubleDQN  # åŒQç½‘ç»œï¼ˆéœ€è¦æ›´æ–°ç‰ˆæœ¬ï¼‰

# æˆ–ä½¿ç”¨å…¶ä»–ç®—æ³•
from stable_baselines3 import A2C, PPO

model = PPO("MlpPolicy", env, ...)  # ä½¿ç”¨PPOä»£æ›¿DQN
```

### å¹¶è¡Œè®­ç»ƒ

```python
from stable_baselines3.common.vec_env import SubprocVecEnv

# åˆ›å»ºå¤šä¸ªå¹¶è¡Œç¯å¢ƒ
def make_env():
    return MovementEnv(server=None, drone_name="UAV1")

env = SubprocVecEnv([make_env for _ in range(4)])  # 4ä¸ªå¹¶è¡Œç¯å¢ƒ
model = DQN("MlpPolicy", env, ...)
```

## ğŸ“ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

### åœ¨AlgorithmServerä¸­ä½¿ç”¨

åœ¨ `AlgorithmServer.py` ä¸­é›†æˆè®­ç»ƒå¥½çš„æ¨¡å‹ï¼š

```python
from stable_baselines3 import DQN

class MultiDroneAlgorithmServer:
    def __init__(self, use_dqn_movement=False):
        # ...
        if use_dqn_movement:
            self.dqn_model = DQN.load("path/to/movement_dqn_final.zip")
    
    def _control_loop(self, drone_name):
        # ä½¿ç”¨DQNé¢„æµ‹åŠ¨ä½œ
        obs = self._get_observation(drone_name)
        action = self.dqn_model.predict(obs, deterministic=True)[0]
        self._apply_action(drone_name, action)
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [Stable-Baselines3 æ–‡æ¡£](https://stable-baselines3.readthedocs.io/)
- [DQNåŸè®ºæ–‡](https://arxiv.org/abs/1312.5602)
- [OpenAI Gym æ–‡æ¡£](https://www.gymlibrary.dev/)

## ğŸ¤ è´¡çŒ®

å¦‚æœæ‚¨æœ‰æ”¹è¿›å»ºè®®æˆ–å‘ç°é—®é¢˜ï¼Œæ¬¢è¿æå‡ºIssueæˆ–Pull Requestã€‚

## ğŸ“„ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-10-14)
- âœ¨ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- ğŸ® æ”¯æŒ6æ–¹å‘ç¦»æ•£åŠ¨ä½œç©ºé—´
- ğŸ“Š 21ç»´çŠ¶æ€è§‚å¯Ÿç©ºé—´
- ğŸ”§ å®Œæ•´çš„é…ç½®ç³»ç»Ÿ
- ğŸ“ˆ è®­ç»ƒå’Œæµ‹è¯•è„šæœ¬
- ğŸ“ å®Œæ•´æ–‡æ¡£

---

**ä½œè€…**: AirsimProject Team  
**æœ€åæ›´æ–°**: 2024-10-14

