{
    "reward_coefficients": {
        "speed_reward": 1.0,
        "speed_penalty_threshold": 1.5,
        "speed_penalty": 1.0,
        "accel_penalty": 0.1,
        "angular_rate_penalty": 0.05,
        "scan_reward": 2.0,
        "out_of_range_penalty": 2.0,
        "action_change_penalty": 0.05,
        "action_magnitude_penalty": 0.01,
        "battery_optimal_reward": 0.5,
        "battery_low_penalty": 1.0
    },
    "thresholds": {
        "scan_entropy_threshold": 30,
        "leader_range_buffer": 0.0,
        "battery_optimal_min": 3.7,
        "battery_optimal_max": 4.0,
        "battery_low_threshold": 3.5
    },
    "episode": {
        "max_steps": 120
    },
    "action_space": {
        "weight_min": 0.5,
        "weight_max": 5.0
    }
}
