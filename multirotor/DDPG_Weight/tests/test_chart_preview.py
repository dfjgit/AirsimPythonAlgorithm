"""
æµ‹è¯•è®­ç»ƒå¯è§†åŒ–å™¨çš„å›¾è¡¨ç”Ÿæˆå’Œé¢„è§ˆåŠŸèƒ½

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ TrainingVisualizer.generate_training_charts() æ–¹æ³•
"""
import sys
import os
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from multirotor.DDPG_Weight.training_visualizer import TrainingVisualizer


def test_chart_generation():
    """æµ‹è¯•å›¾è¡¨ç”ŸæˆåŠŸèƒ½"""
    print("=" * 60)
    print("è®­ç»ƒå¯è§†åŒ–å™¨ - å›¾è¡¨é¢„è§ˆåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨å®ä¾‹ï¼ˆä¸éœ€è¦ server å’Œ envï¼‰
    visualizer = TrainingVisualizer(server=None, env=None)
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    print("\nğŸ“ æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®...")
    
    # æ¨¡æ‹Ÿ 30 ä¸ª episode çš„è®­ç»ƒè¿‡ç¨‹
    for episode in range(30):
        # æ¨¡æ‹Ÿæ¯ä¸ª episode çš„æ­¥æ•°å’Œå¥–åŠ±
        episode_steps = np.random.randint(20, 50)
        base_reward = -100 + episode * 3  # å¥–åŠ±é€æ¸æå‡
        episode_reward = base_reward + np.random.randn() * 10
        
        # æ¨¡æ‹Ÿæ¯æ­¥çš„å¥–åŠ±æ›´æ–°
        for step in range(episode_steps):
            step_reward = np.random.randn() * 2
            visualizer.update_training_stats(
                current_step_reward=step_reward,
                is_episode_done=False
            )
        
        # Episode ç»“æŸ
        visualizer.update_training_stats(
            episode_reward=episode_reward,
            episode_length=episode_steps,
            is_episode_done=True
        )
        
        # æ¨¡æ‹Ÿæƒé‡æ›´æ–°
        if episode % 3 == 0:  # æ¯3ä¸ªepisodeæ›´æ–°ä¸€æ¬¡æƒé‡
            weights = {
                'repulsionCoefficient': 1.0 + np.random.randn() * 0.2,
                'entropyCoefficient': 2.0 + np.random.randn() * 0.3,
                'distanceCoefficient': 1.5 + np.random.randn() * 0.25,
                'leaderRangeCoefficient': 0.8 + np.random.randn() * 0.15,
                'directionRetentionCoefficient': 0.6 + np.random.randn() * 0.1
            }
            visualizer.update_weight_history(weights)
    
    print(f"âœ… å·²ç”Ÿæˆ {visualizer.episode_count} ä¸ª episode çš„æ¨¡æ‹Ÿæ•°æ®")
    print(f"   æ€»æ­¥æ•°: {visualizer.total_steps}")
    print(f"   å¥–åŠ±å†å²: {len(visualizer.reward_history)} æ¡")
    print(f"   æƒé‡æ›´æ–°: {len(visualizer.weight_history['repulsionCoefficient'])} æ¬¡")
    
    # æµ‹è¯•ä¸åŒæ¨¡å¼
    print("\n" + "=" * 60)
    print("ã€æ¨¡å¼ 1ã€‘é¢„è§ˆåæ‰‹åŠ¨ç¡®è®¤æ˜¯å¦ä¿å­˜ï¼ˆæ¨èï¼‰")
    print("=" * 60)
    
    saved_files = visualizer.generate_training_charts(
        preview_before_save=True,   # æ˜¾ç¤ºé¢„è§ˆçª—å£
        auto_save=False              # éœ€è¦ç”¨æˆ·ç¡®è®¤
    )
    
    if saved_files:
        print(f"\nâœ… æˆåŠŸä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶")
        for f in saved_files:
            print(f"   ğŸ“ {f}")
    else:
        print("\nâ„¹ï¸  æœªä¿å­˜æ–‡ä»¶")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


def test_auto_save_mode():
    """æµ‹è¯•è‡ªåŠ¨ä¿å­˜æ¨¡å¼ï¼ˆé¢„è§ˆåè‡ªåŠ¨ä¿å­˜ï¼‰"""
    print("\n" + "=" * 60)
    print("ã€æ¨¡å¼ 2ã€‘é¢„è§ˆåè‡ªåŠ¨ä¿å­˜")
    print("=" * 60)
    
    visualizer = TrainingVisualizer(server=None, env=None)
    
    # ç”Ÿæˆå°‘é‡æµ‹è¯•æ•°æ®
    for episode in range(10):
        episode_steps = 25
        episode_reward = -50 + episode * 5 + np.random.randn() * 5
        
        for step in range(episode_steps):
            visualizer.update_training_stats(current_step_reward=np.random.randn())
        
        visualizer.update_training_stats(
            episode_reward=episode_reward,
            episode_length=episode_steps,
            is_episode_done=True
        )
    
    saved_files = visualizer.generate_training_charts(
        preview_before_save=True,   # æ˜¾ç¤ºé¢„è§ˆ
        auto_save=True               # è‡ªåŠ¨ä¿å­˜
    )
    
    print(f"\nâœ… å·²è‡ªåŠ¨ä¿å­˜æ–‡ä»¶")


def test_no_preview_mode():
    """æµ‹è¯•æ— é¢„è§ˆç›´æ¥ä¿å­˜æ¨¡å¼"""
    print("\n" + "=" * 60)
    print("ã€æ¨¡å¼ 3ã€‘ä¸é¢„è§ˆç›´æ¥ä¿å­˜")
    print("=" * 60)
    
    visualizer = TrainingVisualizer(server=None, env=None)
    
    # ç”Ÿæˆå°‘é‡æµ‹è¯•æ•°æ®
    for episode in range(10):
        episode_steps = 25
        episode_reward = -50 + episode * 5
        
        for step in range(episode_steps):
            visualizer.update_training_stats(current_step_reward=np.random.randn())
        
        visualizer.update_training_stats(
            episode_reward=episode_reward,
            episode_length=episode_steps,
            is_episode_done=True
        )
    
    saved_files = visualizer.generate_training_charts(
        preview_before_save=False,  # ä¸é¢„è§ˆ
        auto_save=False              # æ­¤å‚æ•°æ— æ•ˆï¼Œå› ä¸ºä¸é¢„è§ˆå°±ç›´æ¥ä¿å­˜
    )
    
    print(f"\nâœ… å·²ç›´æ¥ä¿å­˜æ–‡ä»¶ï¼ˆæ— é¢„è§ˆï¼‰")


if __name__ == "__main__":
    try:
        # ä¸»æµ‹è¯•ï¼šé¢„è§ˆåæ‰‹åŠ¨ç¡®è®¤
        test_chart_generation()
        
        # å¦‚æœç”¨æˆ·æƒ³æµ‹è¯•å…¶ä»–æ¨¡å¼ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
        # test_auto_save_mode()
        # test_no_preview_mode()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
