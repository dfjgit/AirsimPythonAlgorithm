# DQN V2 å®ç°æŒ‡å—

åŸºäºæƒé‡é¢„æµ‹çš„è½»é‡çº§å®ç°æ–¹æ¡ˆ

---

## ğŸ¯ æ ¸å¿ƒæ€æƒ³

**ä¸å­¦ä¹ åŠ¨ä½œï¼Œè€Œæ˜¯å­¦ä¹ æƒé‡ï¼**

```
ä¼ ç»ŸDQN:  çŠ¶æ€ â†’ DQN â†’ åŠ¨ä½œ
V2è®¾è®¡:   çŠ¶æ€ â†’ DDPG â†’ æƒé‡ â†’ APF â†’ åŠ¨ä½œ
```

**å…³é”®ä¼˜åŠ¿**:
- åŠ¨ä½œç©ºé—´å°ï¼ˆ5ç»´è¿ç»­ vs 25ç»´ç¦»æ•£ï¼‰
- å……åˆ†åˆ©ç”¨ç°æœ‰APFç®—æ³•
- å¯è§£é‡Šæ€§å¼ºï¼ˆçŸ¥é“ä¸ºä»€ä¹ˆè¿™æ ·é£ï¼‰

---

## ğŸ“ å¿«é€Ÿå®ç°æ­¥éª¤

### æ­¥éª¤1: æ•°æ®æ”¶é›†å™¨ï¼ˆæœ€ç®€ç‰ˆï¼‰

åˆ›å»ºæ–‡ä»¶: `multirotor/DQN/data_collector.py`

```python
"""
è½¨è¿¹æ•°æ®æ”¶é›†å™¨
åœ¨æ­£å¸¸è¿è¡Œæ—¶è®°å½•çŠ¶æ€ã€æƒé‡ã€å¥–åŠ±
"""
import json
import time
import numpy as np
from datetime import datetime


class TrajectoryCollector:
    """æ”¶é›†æ— äººæœºé£è¡Œè½¨è¿¹æ•°æ®ä¾›DQNè®­ç»ƒä½¿ç”¨"""
    
    def __init__(self, output_dir='training/dataset'):
        self.output_dir = output_dir
        self.current_episode = []
        self.episode_count = 0
        
    def start_episode(self):
        """å¼€å§‹æ–°çš„æ•°æ®æ”¶é›†episode"""
        self.current_episode = []
        
    def record_step(self, drone_name, state_dict, weights_dict, reward):
        """
        è®°å½•ä¸€æ­¥æ•°æ®
        
        :param state_dict: {
            'position': [x, y, z],
            'velocity': [vx, vy, vz],
            'entropy_nearby': float,
            'distance_to_leader': float,
            ...
        }
        :param weights_dict: {
            'repulsionCoefficient': float,
            'entropyCoefficient': float,
            ...
        }
        :param reward: float - è¿™ä¸€æ­¥çš„å¥–åŠ±å€¼
        """
        step_data = {
            'timestamp': time.time(),
            'drone_name': drone_name,
            'state': state_dict,
            'weights': weights_dict,
            'reward': reward
        }
        self.current_episode.append(step_data)
    
    def end_episode(self, success=True):
        """ç»“æŸå½“å‰episodeå¹¶ä¿å­˜"""
        if len(self.current_episode) == 0:
            return
        
        # è®¡ç®—episodeç»Ÿè®¡
        total_reward = sum(step['reward'] for step in self.current_episode)
        
        episode_data = {
            'episode_id': self.episode_count,
            'timestamp': datetime.now().isoformat(),
            'steps': len(self.current_episode),
            'total_reward': total_reward,
            'success': success,
            'trajectory': self.current_episode
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        import os
        os.makedirs(self.output_dir, exist_ok=True)
        filename = f"{self.output_dir}/episode_{self.episode_count:04d}.json"
        
        with open(filename, 'w') as f:
            json.dump(episode_data, f, indent=2)
        
        print(f"ä¿å­˜episode {self.episode_count}: {len(self.current_episode)}æ­¥, æ€»å¥–åŠ±: {total_reward:.2f}")
        
        self.episode_count += 1
        self.current_episode = []
```

**ä½¿ç”¨æ–¹æ³•**ï¼ˆåœ¨AlgorithmServerä¸­ï¼‰:
```python
# åœ¨__init__ä¸­
self.data_collector = TrajectoryCollector() if enable_data_collection else None

# åœ¨_process_droneä¸­
if self.data_collector:
    state = self._extract_state(drone_name)
    weights = self._get_current_weights(drone_name)
    reward = self._calculate_reward(drone_name)
    self.data_collector.record_step(drone_name, state, weights, reward)
```

---

### æ­¥éª¤2: çŠ¶æ€æå–å™¨

åˆ›å»ºæ–‡ä»¶: `multirotor/DQN/state_extractor.py`

```python
"""
ä»è¿è¡Œæ—¶æ•°æ®ä¸­æå–DQNçŠ¶æ€å‘é‡
"""
import numpy as np


class StateExtractor:
    """æå–DQNçŠ¶æ€å‘é‡"""
    
    @staticmethod
    def extract(server, drone_name):
        """
        æå–çŠ¶æ€å‘é‡
        
        :return: numpy array, shape=(18,)
        """
        with server.data_lock:
            runtime_data = server.unity_runtime_data[drone_name]
            grid_data = server.grid_data
            
            # 1. æ— äººæœºä½ç½® (3ç»´)
            pos = runtime_data.position
            position = [pos.x, pos.y, pos.z]
            
            # 2. æ— äººæœºé€Ÿåº¦ (3ç»´)
            vel = runtime_data.finalMoveDir * server.config_data.moveSpeed
            velocity = [vel.x, vel.y, vel.z]
            
            # 3. æ— äººæœºæœå‘ (3ç»´)
            fwd = runtime_data.forward
            direction = [fwd.x, fwd.y, fwd.z]
            
            # 4. é™„è¿‘ç†µå€¼ä¿¡æ¯ (3ç»´)
            entropy_info = StateExtractor._get_entropy_info(
                grid_data, pos, server.config_data.scanRadius
            )
            
            # 5. Leaderç›¸å¯¹ä¿¡æ¯ (3ç»´)
            leader_info = [0.0, 0.0, 0.0]
            if runtime_data.leader_position:
                leader_pos = runtime_data.leader_position
                leader_info = [
                    leader_pos.x - pos.x,
                    leader_pos.y - pos.y,
                    leader_pos.z - pos.z
                ]
            
            # 6. æ‰«æè¿›åº¦ (3ç»´)
            scan_info = StateExtractor._get_scan_info(grid_data)
        
        # ç»„åˆçŠ¶æ€å‘é‡ (18ç»´)
        state = np.array(
            position + velocity + direction + 
            entropy_info + leader_info + scan_info,
            dtype=np.float32
        )
        
        return state
    
    @staticmethod
    def _get_entropy_info(grid_data, position, radius):
        """è·å–é™„è¿‘åŒºåŸŸçš„ç†µå€¼ä¿¡æ¯"""
        if not grid_data or not grid_data.cells:
            return [0.0, 0.0, 0.0]
        
        # æ‰¾åˆ°é™„è¿‘çš„å•å…ƒæ ¼
        nearby_cells = [
            cell for cell in grid_data.cells
            if (cell.center - position).magnitude() < radius * 2
        ]
        
        if not nearby_cells:
            return [50.0, 50.0, 0.0]  # é»˜è®¤ä¸­ç­‰ç†µå€¼
        
        entropies = [cell.entropy for cell in nearby_cells]
        
        return [
            np.mean(entropies),      # å¹³å‡ç†µå€¼
            np.max(entropies),       # æœ€å¤§ç†µå€¼
            np.std(entropies)        # ç†µå€¼æ ‡å‡†å·®
        ]
    
    @staticmethod
    def _get_scan_info(grid_data):
        """è·å–æ‰«æè¿›åº¦ä¿¡æ¯"""
        if not grid_data or not grid_data.cells:
            return [0.0, 0.0, 0.0]
        
        total_cells = len(grid_data.cells)
        scanned_cells = sum(1 for cell in grid_data.cells if cell.entropy < 30)
        
        return [
            scanned_cells / max(total_cells, 1),     # æ‰«ææ¯”ä¾‹
            scanned_cells,                           # å·²æ‰«ææ•°é‡
            total_cells - scanned_cells              # æœªæ‰«ææ•°é‡
        ]
```

---

### æ­¥éª¤3: è½»é‡çº§æ¨ç†å™¨

åˆ›å»ºæ–‡ä»¶: `multirotor/DQN/weight_predictor.py`

```python
"""
è½»é‡çº§æƒé‡é¢„æµ‹å™¨ï¼ˆONNXæ¨ç†ï¼‰
"""
import os
import numpy as np


class WeightPredictor:
    """ä½¿ç”¨ONNXæ¨¡å‹é¢„æµ‹APFæƒé‡ç³»æ•°"""
    
    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        :param model_path: ONNXæ¨¡å‹è·¯å¾„
        """
        self.session = None
        self.model_loaded = False
        
        if model_path and os.path.exists(model_path):
            self._load_model(model_path)
    
    def _load_model(self, model_path):
        """åŠ è½½ONNXæ¨¡å‹"""
        try:
            import onnxruntime as ort
            
            # åˆ›å»ºæ¨ç†ä¼šè¯ï¼ˆå¼ºåˆ¶CPUï¼‰
            self.session = ort.InferenceSession(
                model_path,
                providers=['CPUExecutionProvider']
            )
            
            self.input_name = self.session.get_inputs()[0].name
            self.output_name = self.session.get_outputs()[0].name
            
            self.model_loaded = True
            print(f"âœ“ æƒé‡é¢„æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            
        except ImportError:
            print("âš  onnxruntimeæœªå®‰è£…ï¼Œæƒé‡é¢„æµ‹åŠŸèƒ½ä¸å¯ç”¨")
            print("  å®‰è£…æ–¹æ³•: pip install onnxruntime")
        except Exception as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
    
    def predict(self, state):
        """
        é¢„æµ‹APFæƒé‡ç³»æ•°
        
        :param state: numpy array, shape=(18,)
        :return: dict with weight coefficients
        """
        if not self.model_loaded or self.session is None:
            return None
        
        try:
            # ç¡®ä¿è¾“å…¥shapeæ­£ç¡®
            if len(state.shape) == 1:
                state = state.reshape(1, -1)
            
            # ONNXæ¨ç†
            output = self.session.run(
                [self.output_name],
                {self.input_name: state.astype(np.float32)}
            )
            
            # è¾“å‡º: [Î±1, Î±2, Î±3, Î±4, Î±5]
            weights = output[0][0]
            
            return {
                'repulsionCoefficient': float(weights[0]),
                'entropyCoefficient': float(weights[1]),
                'distanceCoefficient': float(weights[2]),
                'leaderRangeCoefficient': float(weights[3]),
                'directionRetentionCoefficient': float(weights[4])
            }
            
        except Exception as e:
            print(f"æƒé‡é¢„æµ‹å¤±è´¥: {str(e)}")
            return None
    
    def is_available(self):
        """æ£€æŸ¥é¢„æµ‹å™¨æ˜¯å¦å¯ç”¨"""
        return self.model_loaded


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = WeightPredictor("models/weight_predictor_quantized.onnx")
    
    if predictor.is_available():
        # åˆ›å»ºæµ‹è¯•çŠ¶æ€
        test_state = np.random.randn(18).astype(np.float32)
        
        # é¢„æµ‹æƒé‡
        weights = predictor.predict(test_state)
        
        print("é¢„æµ‹çš„APFæƒé‡:")
        for key, value in weights.items():
            print(f"  {key}: {value:.2f}")
    else:
        print("é¢„æµ‹å™¨ä¸å¯ç”¨")
```

---

### æ­¥éª¤4: å¥–åŠ±è®¡ç®—å™¨

åˆ›å»ºæ–‡ä»¶: `multirotor/DQN/reward_calculator.py`

```python
"""
å¥–åŠ±å‡½æ•°è®¡ç®—å™¨
æ ¹æ®æ— äººæœºè¡Œä¸ºè®¡ç®—å¥–åŠ±å€¼
"""
import numpy as np


class RewardCalculator:
    """è®¡ç®—å¼ºåŒ–å­¦ä¹ å¥–åŠ±"""
    
    def __init__(self, config):
        self.config = config
        # å¥–åŠ±æƒé‡
        self.w_exploration = 1.0      # æ¢ç´¢å¥–åŠ±
        self.w_efficiency = 0.5       # æ•ˆç‡å¥–åŠ±
        self.w_collision = -5.0       # ç¢°æ’æƒ©ç½š
        self.w_boundary = -2.0        # è¶Šç•Œæƒ©ç½š
        self.w_smooth = 0.3           # å¹³æ»‘è¿åŠ¨å¥–åŠ±
        
        # è®°å½•ä¸Šä¸€æ­¥çŠ¶æ€
        self.prev_scanned_area = {}
        self.prev_position = {}
    
    def calculate(self, drone_name, server):
        """
        è®¡ç®—å½“å‰æ­¥çš„å¥–åŠ±
        
        :return: float - å¥–åŠ±å€¼
        """
        reward = 0.0
        
        with server.data_lock:
            runtime_data = server.unity_runtime_data[drone_name]
            grid_data = server.grid_data
            
            # 1. æ¢ç´¢å¥–åŠ±ï¼ˆæ–°æ‰«æåŒºåŸŸï¼‰
            current_scanned = self._count_scanned_cells(grid_data)
            if drone_name in self.prev_scanned_area:
                new_scanned = current_scanned - self.prev_scanned_area[drone_name]
                reward += self.w_exploration * new_scanned
            self.prev_scanned_area[drone_name] = current_scanned
            
            # 2. ç¢°æ’æƒ©ç½š
            min_distance = self._get_min_distance_to_others(runtime_data)
            if min_distance < self.config.minSafeDistance:
                reward += self.w_collision * (self.config.minSafeDistance - min_distance)
            
            # 3. è¶Šç•Œæƒ©ç½š
            if runtime_data.leader_position:
                distance_to_leader = (runtime_data.position - runtime_data.leader_position).magnitude()
                if distance_to_leader > runtime_data.leader_scan_radius:
                    reward += self.w_boundary * (distance_to_leader - runtime_data.leader_scan_radius)
            
            # 4. å¹³æ»‘è¿åŠ¨å¥–åŠ±
            if drone_name in self.prev_position:
                movement = (runtime_data.position - self.prev_position[drone_name]).magnitude()
                # å¥–åŠ±ç¨³å®šçš„ç§»åŠ¨é€Ÿåº¦
                ideal_movement = self.config.moveSpeed * self.config.updateInterval
                smoothness = 1.0 - abs(movement - ideal_movement) / ideal_movement
                reward += self.w_smooth * max(0, smoothness)
            self.prev_position[drone_name] = runtime_data.position
        
        return reward
    
    def _count_scanned_cells(self, grid_data):
        """ç»Ÿè®¡å·²æ‰«æå•å…ƒæ ¼æ•°é‡"""
        if not grid_data or not grid_data.cells:
            return 0
        return sum(1 for cell in grid_data.cells if cell.entropy < 30)
    
    def _get_min_distance_to_others(self, runtime_data):
        """è·å–åˆ°å…¶ä»–æ— äººæœºçš„æœ€å°è·ç¦»"""
        if not runtime_data.otherScannerPositions:
            return float('inf')
        
        distances = [
            (runtime_data.position - other_pos).magnitude()
            for other_pos in runtime_data.otherScannerPositions
        ]
        return min(distances) if distances else float('inf')
```

---

### æ­¥éª¤5: é›†æˆåˆ°AlgorithmServer

ä¿®æ”¹ `multirotor/AlgorithmServer.py`:

```python
class MultiDroneAlgorithmServer:
    def __init__(self, config_file=None, drone_names=None, 
                 use_weight_prediction=False, 
                 collect_training_data=False):
        """
        :param use_weight_prediction: æ˜¯å¦ä½¿ç”¨æ¨¡å‹é¢„æµ‹æƒé‡
        :param collect_training_data: æ˜¯å¦æ”¶é›†è®­ç»ƒæ•°æ®
        """
        # ... ç°æœ‰åˆå§‹åŒ– ...
        
        # DQN V2ç›¸å…³
        self.use_weight_prediction = use_weight_prediction
        self.weight_predictor = None
        
        if use_weight_prediction:
            self._init_weight_predictor()
        
        # æ•°æ®æ”¶é›†
        self.collect_training_data = collect_training_data
        self.data_collector = None
        self.reward_calculator = None
        
        if collect_training_data:
            from multirotor.DQN.data_collector import TrajectoryCollector
            from multirotor.DQN.reward_calculator import RewardCalculator
            self.data_collector = TrajectoryCollector()
            self.reward_calculator = RewardCalculator(self.config_data)
            self.data_collector.start_episode()
    
    def _init_weight_predictor(self):
        """åˆå§‹åŒ–æƒé‡é¢„æµ‹å™¨ï¼ˆONNXï¼‰"""
        try:
            from multirotor.DQN.weight_predictor import WeightPredictor
            
            model_path = os.path.join(
                os.path.dirname(__file__),
                'DQN', 'models', 'weight_predictor.onnx'
            )
            
            self.weight_predictor = WeightPredictor(model_path)
            
            if self.weight_predictor.is_available():
                logger.info("æƒé‡é¢„æµ‹æ¨¡å¼å·²å¯ç”¨")
            else:
                logger.warning("æƒé‡é¢„æµ‹æ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶æƒé‡")
                self.use_weight_prediction = False
                
        except Exception as e:
            logger.error(f"æƒé‡é¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.use_weight_prediction = False
    
    def _get_apf_weights(self, drone_name):
        """è·å–APFæƒé‡ï¼ˆå¯èƒ½æ¥è‡ªæ¨¡å‹é¢„æµ‹ï¼‰"""
        if self.use_weight_prediction and self.weight_predictor:
            # æå–çŠ¶æ€
            from multirotor.DQN.state_extractor import StateExtractor
            state = StateExtractor.extract(self, drone_name)
            
            # é¢„æµ‹æƒé‡
            weights = self.weight_predictor.predict(state)
            
            if weights:
                return weights
        
        # å›é€€åˆ°é…ç½®æ–‡ä»¶æƒé‡
        return {
            'repulsionCoefficient': self.config_data.repulsionCoefficient,
            'entropyCoefficient': self.config_data.entropyCoefficient,
            'distanceCoefficient': self.config_data.distanceCoefficient,
            'leaderRangeCoefficient': self.config_data.leaderRangeCoefficient,
            'directionRetentionCoefficient': self.config_data.directionRetentionCoefficient
        }
    
    def _process_drone(self, drone_name):
        """æ— äººæœºå¤„ç†çº¿ç¨‹ï¼ˆæ”¯æŒæƒé‡é¢„æµ‹å’Œæ•°æ®æ”¶é›†ï¼‰"""
        while self.running:
            try:
                # ... ç°æœ‰çš„æ•°æ®æ£€æŸ¥ ...
                
                # è·å–å½“å‰æƒé‡ï¼ˆå¯èƒ½æ¥è‡ªæ¨¡å‹é¢„æµ‹ï¼‰
                weights = self._get_apf_weights(drone_name)
                
                # è®¾ç½®åˆ°APFç®—æ³•
                self.algorithms[drone_name].set_coefficients(weights)
                
                # æ‰§è¡ŒAPFç®—æ³•
                final_dir = self.algorithms[drone_name].update_runtime_data(
                    self.grid_data, self.unity_runtime_data[drone_name]
                )
                
                # æ•°æ®æ”¶é›†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.data_collector and self.reward_calculator:
                    from multirotor.DQN.state_extractor import StateExtractor
                    state_dict = StateExtractor.extract(self, drone_name)
                    reward = self.reward_calculator.calculate(drone_name, self)
                    self.data_collector.record_step(drone_name, state_dict, weights, reward)
                
                # æ§åˆ¶æ— äººæœºç§»åŠ¨
                self._control_drone_movement(drone_name, final_dir.finalMoveDir)
                
                # å‘é€æ•°æ®åˆ°Unity
                self._send_processed_data(drone_name, final_dir)
                
                time.sleep(self.config_data.updateInterval)
                
            except Exception as e:
                logger.error(f"æ— äººæœº{drone_name}å¤„ç†å‡ºé”™: {str(e)}")
                time.sleep(self.config_data.updateInterval)
```

---

## ğŸš€ ä½¿ç”¨æµç¨‹

### é˜¶æ®µA: æ•°æ®æ”¶é›†ï¼ˆ1-2å‘¨ï¼‰

```bash
# å¯ç”¨æ•°æ®æ”¶é›†æ¨¡å¼è¿è¡Œ
python multirotor/AlgorithmServer.py --collect-data

# è¿è¡Œå¤šæ¬¡ï¼Œæ”¶é›†ä¸åŒåœºæ™¯çš„æ•°æ®
# - å¼€é˜”åŒºåŸŸ
# - å¯†é›†éšœç¢ç‰©
# - å¤šæ— äººæœº
# ç­‰

# æ•°æ®ä¼šä¿å­˜åˆ° training/dataset/ ç›®å½•
```

### é˜¶æ®µB: è®­ç»ƒï¼ˆåœ¨GPUç¯å¢ƒï¼‰

```bash
# åœ¨æœ‰GPUçš„æœºå™¨ä¸Š
cd training/
python train_ddpg.py --data-dir dataset/ --epochs 1000

# è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆ
# - weight_predictor.pth (PyTorchæ¨¡å‹)
# - weight_predictor.onnx (ONNXæ¨¡å‹)
# - weight_predictor_quantized.onnx (é‡åŒ–æ¨¡å‹)
```

### é˜¶æ®µC: éƒ¨ç½²ï¼ˆç›®æ ‡æœºå™¨ï¼‰

```bash
# 1. å¤åˆ¶æ¨¡å‹æ–‡ä»¶
cp weight_predictor_quantized.onnx multirotor/DQN/models/

# 2. å®‰è£…ONNX Runtimeï¼ˆè½»é‡çº§ï¼‰
pip install onnxruntime

# 3. å¯ç”¨æƒé‡é¢„æµ‹æ¨¡å¼
python multirotor/AlgorithmServer.py --use-weight-prediction

# 4. è§‚å¯Ÿæ•ˆæœ
# ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨æ¨¡å‹é¢„æµ‹æƒé‡ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒå‚
```

---

## ğŸ“Š é¢„æœŸæ€§èƒ½

### æ¨ç†æ€§èƒ½

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|------|--------|------|
| **æ¨ç†å»¶è¿Ÿ** | < 10ms | ONNX INT8é‡åŒ–æ¨¡å‹ |
| **CPUå ç”¨** | +3-5% | ç›¸æ¯”çº¯APFçš„å¢åŠ  |
| **å†…å­˜å ç”¨** | +50MB | ONNX Runtime + æ¨¡å‹ |
| **æ¨¡å‹å¤§å°** | < 2MB | é‡åŒ–å |

### æ•ˆæœæå‡

| æŒ‡æ ‡ | å›ºå®šæƒé‡ | å­¦ä¹ æƒé‡ | æå‡ |
|------|----------|----------|------|
| **æ‰«æè¦†ç›–ç‡** | 85% | 93% | +8% |
| **æ‰«ææ—¶é—´** | 300s | 270s | -10% |
| **è·¯å¾„æ•ˆç‡** | åŸºçº¿ | +15% | +15% |
| **è‡ªé€‚åº”æ€§** | ä½ | é«˜ | ğŸŒŸ |

---

## ğŸ“ æŠ€æœ¯è¦ç‚¹

### 1. ä¸ºä»€ä¹ˆæ˜¯5ä¸ªæƒé‡ï¼Ÿ

å¯¹åº”APFç®—æ³•çš„5ä¸ªæƒé‡ç³»æ•°ï¼š
- **Î±1** = repulsionCoefficient (æ’æ–¥åŠ›)
- **Î±2** = entropyCoefficient (ç†µ)
- **Î±3** = distanceCoefficient (è·ç¦»)
- **Î±4** = leaderRangeCoefficient (LeaderèŒƒå›´)
- **Î±5** = directionRetentionCoefficient (æ–¹å‘ä¿æŒ)

### 2. DDPGç½‘ç»œè¾“å‡ºèŒƒå›´

```python
# Actorç½‘ç»œè¾“å‡º
raw_output = self.actor(state)  # èŒƒå›´: (-âˆ, +âˆ)

# ä½¿ç”¨Sigmoidç¼©æ”¾åˆ° [0.1, 10.0]
weights = torch.sigmoid(raw_output) * 9.9 + 0.1
```

### 3. æ•°æ®æ”¶é›†ç­–ç•¥

**å¤šæ ·åŒ–é‡‡é›†**:
- ä½¿ç”¨ä¸åŒçš„å›ºå®šæƒé‡é…ç½®è¿è¡Œ
- è®°å½•å¥½çš„å’Œåçš„è¡Œä¸º
- åŒ…å«è¾¹ç•Œæƒ…å†µ

**æ•°æ®æ ‡æ³¨**:
- æ¯æ­¥è‡ªåŠ¨è®¡ç®—å¥–åŠ±
- è®°å½•æœ€ç»ˆä»»åŠ¡æˆåŠŸ/å¤±è´¥
- ä¿å­˜å®Œæ•´è½¨è¿¹

---

## ğŸ› ï¸ å¼€å‘å·¥å…·

### è®­ç»ƒè„šæœ¬æ¨¡æ¿

åˆ›å»ºæ–‡ä»¶: `training/train_ddpg.py`

```python
"""
DDPGè®­ç»ƒè„šæœ¬
"""
import argparse
from stable_baselines3 import DDPG
from weight_learning_env import WeightLearningEnv


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data-dir', default='dataset/', help='è®­ç»ƒæ•°æ®ç›®å½•')
    parser.add_argument('--epochs', type=int, default=1000, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--save-path', default='weight_predictor', help='æ¨¡å‹ä¿å­˜è·¯å¾„')
    args = parser.parse_args()
    
    print("=" * 60)
    print("DDPGè®­ç»ƒ - APFæƒé‡é¢„æµ‹")
    print("=" * 60)
    
    # åˆ›å»ºç¯å¢ƒ
    env = WeightLearningEnv(data_dir=args.data_dir)
    print(f"ç¯å¢ƒåˆ›å»ºæˆåŠŸ: state_dim={env.state_dim}, action_dim={env.action_dim}")
    
    # åˆ›å»ºDDPGæ¨¡å‹
    model = DDPG(
        "MlpPolicy",
        env,
        learning_rate=1e-3,
        buffer_size=100000,
        batch_size=256,
        gamma=0.99,
        tau=0.005,
        verbose=1,
        tensorboard_log="./logs/"
    )
    
    # è®­ç»ƒ
    print(f"\nå¼€å§‹è®­ç»ƒ {args.epochs} è½®...")
    model.learn(total_timesteps=args.epochs * 1000)
    
    # ä¿å­˜PyTorchæ¨¡å‹
    model.save(args.save_path)
    print(f"\næ¨¡å‹å·²ä¿å­˜: {args.save_path}.zip")
    
    # è½¬æ¢ä¸ºONNX
    print("\nè½¬æ¢ä¸ºONNXæ ¼å¼...")
    export_to_onnx(model, args.save_path + ".onnx")
    
    print("\nâœ“ è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
```

---

## ğŸ“¦ ä¾èµ–ç®¡ç†

### è®­ç»ƒç¯å¢ƒä¾èµ–

åˆ›å»ºæ–‡ä»¶: `training/requirements.txt`

```
# æ·±åº¦å­¦ä¹ æ¡†æ¶
torch>=1.9.0
stable-baselines3>=1.0
tensorboard>=2.0

# æ•°æ®å¤„ç†
numpy>=1.19.0
pandas>=1.2.0

# æ¨¡å‹è½¬æ¢
onnx>=1.10.0
onnx-simplifier>=0.3.0

# å¯è§†åŒ–
matplotlib>=3.3.0
seaborn>=0.11.0
```

### æ¨ç†ç¯å¢ƒä¾èµ–

æ›´æ–° `requirements.txt`:

```
# ... ç°æœ‰ä¾èµ– ...

# DQNæƒé‡é¢„æµ‹ï¼ˆå¯é€‰ï¼‰
onnxruntime>=1.10.0  # è½»é‡çº§æ¨ç†å¼•æ“
```

---

## âœ… æ£€æŸ¥æ¸…å•

### å¼€å‘å‰æ£€æŸ¥
- [ ] ç†è§£V2è®¾è®¡ç†å¿µ
- [ ] å‡†å¤‡GPUè®­ç»ƒç¯å¢ƒï¼ˆæˆ–ä½¿ç”¨Colabï¼‰
- [ ] äº†è§£DDPGç®—æ³•åŸç†
- [ ] ç†Ÿæ‚‰ONNXæ¨¡å‹éƒ¨ç½²

### æ•°æ®æ”¶é›†æ£€æŸ¥
- [ ] æ•°æ®æ”¶é›†å™¨å®ç°æ­£ç¡®
- [ ] çŠ¶æ€æå–å®Œæ•´
- [ ] å¥–åŠ±è®¡ç®—åˆç†
- [ ] è‡³å°‘æ”¶é›†100ä¸ªepisode

### è®­ç»ƒæ£€æŸ¥
- [ ] è®­ç»ƒç¯å¢ƒæ­å»ºå®Œæˆ
- [ ] DDPGæ”¶æ•›æ­£å¸¸
- [ ] æƒé‡è¾“å‡ºåœ¨æœ‰æ•ˆèŒƒå›´å†…
- [ ] è®­ç»ƒæ›²çº¿åˆç†

### éƒ¨ç½²æ£€æŸ¥
- [ ] ONNXæ¨¡å‹è½¬æ¢æˆåŠŸ
- [ ] é‡åŒ–æ¨¡å‹å¤§å°åˆç†
- [ ] CPUæ¨ç†é€Ÿåº¦æ»¡è¶³è¦æ±‚
- [ ] é›†æˆæ— æŠ¥é”™

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### æœ€ä½æ ‡å‡†ï¼ˆMVPï¼‰
- âœ… èƒ½æ”¶é›†è®­ç»ƒæ•°æ®
- âœ… èƒ½è®­ç»ƒå‡ºæ”¶æ•›çš„æ¨¡å‹
- âœ… èƒ½è½¬æ¢ä¸ºONNXå¹¶æ¨ç†
- âœ… æ¨ç†å»¶è¿Ÿ< 50ms

### ç†æƒ³æ ‡å‡†
- âœ… æ‰«ææ•ˆç‡æå‡> 10%
- âœ… CPUå ç”¨å¢åŠ < 5%
- âœ… é€‚åº”ä¸åŒåœºæ™¯
- âœ… ç¨³å®šè¿è¡Œæ— å´©æºƒ

---

**è®¾è®¡å®Œæˆæ—¥æœŸ**: 2025-10-13  
**ä¸‹ä¸€æ­¥**: å®ç°æ•°æ®æ”¶é›†å™¨å¹¶å¼€å§‹æ”¶é›†æ•°æ®

